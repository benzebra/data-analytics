{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617002, 27)\n",
      "train idx:  [ 23754 272651 328894 ... 523435 430660 552899]\n",
      "val idx:  [ 93259  45326 396437 ... 523991 398025 211949]\n",
      "n splits:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#encode categorical and numerical columns with label and ordinal encoding\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "import numpy as np\n",
    "#do random forest classification\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split,PredefinedSplit\n",
    "\n",
    "\n",
    "seed = 42\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "print(\"train idx: \",train_idx)\n",
    "print(\"val idx: \",val_idx)\n",
    "print(\"n splits: \",ps.get_n_splits())\n",
    "\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "X = pca.transform(X)\n",
    "\n",
    "# Apply PCA transformation to and X_val\n",
    "X_val = pca.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import pickle\n",
    "\n",
    "# scoring = ['balanced_accuracy','f1_weighted']\n",
    "\n",
    "# param_grid = {'C': [0.1, 1,10,100,1000], \n",
    "#               'gamma': [1,0.1,0.01,0.001],\n",
    "#               'kernel': ['rbf','sigmoid','linear']}  \n",
    "\n",
    "# #cast x and y train in numpy arrays\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# grid = GridSearchCV(SVC(random_state=seed), param_grid,verbose=10,cv=ps,n_jobs=-1,scoring=scoring)\n",
    "# grid.fit(X_train, y_train)\n",
    "# file = open(\"svc.save\",\"wb\")\n",
    "# pickle.dump(grid.best_estimator_, file)\n",
    "# print(\"Best hypearparameters: \",grid.best_estimator_)\n",
    "# print(\"Best performance:\",  grid.best_score_)\n",
    "# file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import random forest classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import pickle\n",
    "\n",
    "# param_grid = {  'n_estimators': [100, 200],\n",
    "#                 'criterion': ['gini', 'entropy']\n",
    "#                 }  \n",
    "\n",
    "# scoring = ['balanced_accuracy','f1_weighted']\n",
    "\n",
    "# grid = GridSearchCV(RandomForestClassifier(random_state=seed,n_jobs=-1), param_grid,verbose=10,cv=ps,n_jobs=-1,scoring=scoring, refit='balanced_accuracy')\n",
    "# grid.fit(X, y)\n",
    "# file = open(\"rf.save\",\"wb\")\n",
    "# pickle.dump(grid.best_estimator_, file)\n",
    "# print(\"Best hyperparameters: \",grid.best_estimator_)\n",
    "# print(\"Best performance:\",  grid.best_score_)\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1; 1/1] START n_neighbors=15, p=1.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinal\\Desktop\\UNIBO\\DA\\data-analytics\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\rinal\\Desktop\\UNIBO\\DA\\data-analytics\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/1; 1/1] END n_neighbors=15, p=1; balanced_accuracy: (test=0.977) f1_weighted: (test=0.997) total time= 1.6min\n",
      "Best hyperparameters:  KNeighborsClassifier(n_neighbors=15, p=1)\n",
      "Best performance: 0.9771813550423756\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#do the same with knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "param_grid = {'n_neighbors': [15],\n",
    "            'p': [1]}\n",
    "scoring = ['balanced_accuracy','f1_weighted']\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid,verbose=10,cv=ps,scoring=scoring, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "#save the best model\n",
    "print(\"Best hyperparameters: \",grid.best_estimator_)\n",
    "print(\"Best performance:\",  grid.best_score_)\n",
    "#save the model with the best hyperparameters\n",
    "file = open(\"knn.save\",\"wb\")\n",
    "pickle.dump(grid.best_estimator_, file)\n",
    "file.close()\n",
    "\n",
    "#do prediction on the validation set\n",
    "y_pred = grid.predict(X_val)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "#drop balanced_accuracy and f1_weighted\n",
    "\n",
    "#balanced_accuracy print\n",
    "print(\"balanced_accuracy: \",grid.cv_results_['mean_test_balanced_accuracy'][grid.best_index_])\n",
    "#f1_weighted print\n",
    "print(\"f1_weighted: \",grid.cv_results_['mean_test_f1_weighted'][grid.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#do prediction on the validation set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_val, y_pred)\n\u001b[0;32m      4\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm)\n",
      "File \u001b[1;32mc:\\Users\\rinal\\Desktop\\UNIBO\\DA\\data-analytics\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:596\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_search_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \n\u001b[0;32m    581\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\rinal\\Desktop\\UNIBO\\DA\\data-analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
