{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import preprocessing, decomposition\n",
    "\n",
    "seed = 42\n",
    "FILENAME = \"train_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read_csv\n",
    "# 2. dropna\n",
    "# 3. drop label\n",
    "# 4. replace src_bytes\n",
    "# 5. casting \n",
    "# 6. encoding (cat/num)\n",
    "# 7. extract y \n",
    "# 8. drop type\n",
    "# 9. label encoding on y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617002, 27)\n"
     ]
    }
   ],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44900607e-01 1.33969802e-01 1.33675083e-01 4.92563102e-02\n",
      " 4.70841450e-02 4.61255229e-02 4.54983184e-02 4.23647696e-02\n",
      " 3.90549396e-02 3.04763781e-02 2.33517088e-02 2.29889283e-02\n",
      " 2.21947914e-02 2.17003153e-02 2.08727979e-02 2.00212553e-02\n",
      " 1.97292747e-02 1.88016761e-02 1.76938953e-02 1.65682323e-02\n",
      " 1.54616886e-02 1.51850213e-02 9.87827754e-03 7.51437108e-03\n",
      " 6.96394655e-03 5.98062813e-03 5.02077679e-03 4.85400224e-03\n",
      " 2.14769257e-03 2.05417698e-03 1.90607313e-03 1.43796611e-03\n",
      " 1.20337627e-03 1.14801797e-03 9.00030610e-04 7.01092490e-04\n",
      " 3.94912281e-04 3.89787902e-04 3.12938584e-04 1.14936749e-04\n",
      " 1.01535087e-04]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[CV 1/1; 3/6] START criterion=gini, n_estimators=200............................\n",
      "[CV 1/1; 1/6] START criterion=gini, n_estimators=50.............................\n",
      "[CV 1/1; 5/6] START criterion=entropy, n_estimators=100.........................\n",
      "[CV 1/1; 4/6] START criterion=entropy, n_estimators=50..........................\n",
      "[CV 1/1; 2/6] START criterion=gini, n_estimators=100............................\n",
      "[CV 1/1; 6/6] START criterion=entropy, n_estimators=200.........................\n",
      "[CV 1/1; 1/6] END criterion=gini, n_estimators=50; balanced_accuracy: (test=0.998) f1_weighted: (test=0.999) total time= 3.5min\n",
      "[CV 1/1; 4/6] END criterion=entropy, n_estimators=50; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time= 3.7min\n",
      "[CV 1/1; 2/6] END criterion=gini, n_estimators=100; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time= 6.6min\n",
      "[CV 1/1; 5/6] END criterion=entropy, n_estimators=100; balanced_accuracy: (test=0.998) f1_weighted: (test=0.999) total time= 6.8min\n",
      "[CV 1/1; 3/6] END criterion=gini, n_estimators=200; balanced_accuracy: (test=0.998) f1_weighted: (test=0.999) total time=11.5min\n",
      "[CV 1/1; 6/6] END criterion=entropy, n_estimators=200; balanced_accuracy: (test=0.998) f1_weighted: (test=0.999) total time=11.6min\n",
      "---------------------------------\n",
      "Best hyper:  RandomForestClassifier(criterion='entropy')\n",
      "Best score:  0.998457141298475\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617002, 27)\n"
     ]
    }
   ],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[CV 1/1; 5/6] START criterion=entropy, n_estimators=100.........................\n",
      "[CV 1/1; 2/6] START criterion=gini, n_estimators=100............................\n",
      "[CV 1/1; 3/6] START criterion=gini, n_estimators=200............................\n",
      "[CV 1/1; 6/6] START criterion=entropy, n_estimators=200.........................\n",
      "[CV 1/1; 1/6] START criterion=gini, n_estimators=50.............................\n",
      "[CV 1/1; 4/6] START criterion=entropy, n_estimators=50..........................\n",
      "[CV 1/1; 4/6] END criterion=entropy, n_estimators=50; balanced_accuracy: (test=0.996) f1_weighted: (test=1.000) total time=  21.8s\n",
      "[CV 1/1; 1/6] END criterion=gini, n_estimators=50; balanced_accuracy: (test=0.996) f1_weighted: (test=1.000) total time=  22.0s\n",
      "[CV 1/1; 2/6] END criterion=gini, n_estimators=100; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time=  38.4s\n",
      "[CV 1/1; 5/6] END criterion=entropy, n_estimators=100; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time=  39.4s\n",
      "[CV 1/1; 6/6] END criterion=entropy, n_estimators=200; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time= 1.1min\n",
      "[CV 1/1; 3/6] END criterion=gini, n_estimators=200; balanced_accuracy: (test=0.996) f1_weighted: (test=1.000) total time= 1.1min\n",
      "---------------------------------\n",
      "Best hyper:  RandomForestClassifier(criterion='entropy')\n",
      "Best score:  0.9973716241067431\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.93179913e+00,  4.00022674e+00, -5.21043260e+00, ...,\n",
       "        -1.35574797e-01,  3.79912781e+00, -3.88745483e+00],\n",
       "       [-2.08636621e+00, -3.32270786e-01, -5.36121959e+00, ...,\n",
       "        -6.07465354e+00, -1.99182280e+00, -3.75603546e-01],\n",
       "       [-1.00060058e+00, -2.25348998e+00,  4.80439269e-03, ...,\n",
       "         2.21397783e-01, -7.41315988e-01, -6.65059856e-01],\n",
       "       ...,\n",
       "       [ 3.02597595e+00, -2.43900247e+00, -7.13637327e-01, ...,\n",
       "        -9.33429989e-01, -6.84175604e-01, -1.04748961e+00],\n",
       "       [ 4.57737595e+00, -1.49195803e+00, -2.10543630e+00, ...,\n",
       "        -1.85218219e+00,  4.36944697e+00,  1.91918828e+00],\n",
       "       [ 3.44310869e+00, -2.21994280e+00, -8.77555638e-01, ...,\n",
       "         1.14568784e+00, -1.37160912e-01, -9.56462870e-01]],\n",
       "      shape=(617002, 9))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# X = pca.transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[CV 1/1; 2/6] START criterion=gini, n_estimators=100............................\n",
      "[CV 1/1; 1/6] START criterion=gini, n_estimators=50.............................\n",
      "[CV 1/1; 5/6] START criterion=entropy, n_estimators=100.........................\n",
      "[CV 1/1; 4/6] START criterion=entropy, n_estimators=50..........................\n",
      "[CV 1/1; 3/6] START criterion=gini, n_estimators=200............................\n",
      "[CV 1/1; 6/6] START criterion=entropy, n_estimators=200.........................\n",
      "[CV 1/1; 4/6] END criterion=entropy, n_estimators=50; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time=  22.6s\n",
      "[CV 1/1; 1/6] END criterion=gini, n_estimators=50; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time=  23.0s\n",
      "[CV 1/1; 5/6] END criterion=entropy, n_estimators=100; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time=  39.0s\n",
      "[CV 1/1; 2/6] END criterion=gini, n_estimators=100; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time=  39.8s\n",
      "[CV 1/1; 6/6] END criterion=entropy, n_estimators=200; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time= 1.1min\n",
      "[CV 1/1; 3/6] END criterion=gini, n_estimators=200; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time= 1.1min\n",
      "---------------------------------\n",
      "Best hyper:  RandomForestClassifier()\n",
      "Best score:  0.9981141489506052\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617002, 27)\n"
     ]
    }
   ],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "\n",
    "X = pca.transform(X)\n",
    "\n",
    "# lda = LinearDiscriminantAnalysis()\n",
    "# lda.fit(X_train, y_train)\n",
    "# lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n",
      "[CV 1/1; 8/40] START C=0.1, gamma=auto, kernel=sigmoid..........................\n",
      "[CV 1/1; 3/40] START C=0.1, gamma=scale, kernel=poly............................\n",
      "[CV 1/1; 7/40] START C=0.1, gamma=auto, kernel=poly.............................\n",
      "[CV 1/1; 4/40] START C=0.1, gamma=scale, kernel=sigmoid.........................[CV 1/1; 6/40] START C=0.1, gamma=auto, kernel=rbf..............................\n",
      "\n",
      "[CV 1/1; 5/40] START C=0.1, gamma=auto, kernel=linear...........................\n",
      "[CV 1/1; 1/40] START C=0.1, gamma=scale, kernel=linear..........................\n",
      "[CV 1/1; 2/40] START C=0.1, gamma=scale, kernel=rbf.............................\n",
      "[CV 1/1; 1/40] END C=0.1, gamma=scale, kernel=linear; balanced_accuracy: (test=0.942) f1_weighted: (test=0.988) total time=28.4min\n",
      "[CV 1/1; 9/40] START C=1, gamma=scale, kernel=linear............................\n",
      "[CV 1/1; 5/40] END C=0.1, gamma=auto, kernel=linear; balanced_accuracy: (test=0.942) f1_weighted: (test=0.988) total time=28.4min\n",
      "[CV 1/1; 10/40] START C=1, gamma=scale, kernel=rbf..............................\n",
      "[CV 1/1; 10/40] END C=1, gamma=scale, kernel=rbf; balanced_accuracy: (test=0.958) f1_weighted: (test=0.994) total time=28.9min\n",
      "[CV 1/1; 11/40] START C=1, gamma=scale, kernel=poly.............................\n",
      "[CV 1/1; 9/40] END C=1, gamma=scale, kernel=linear; balanced_accuracy: (test=0.943) f1_weighted: (test=0.989) total time=36.6min\n",
      "[CV 1/1; 12/40] START C=1, gamma=scale, kernel=sigmoid..........................\n",
      "[CV 1/1; 6/40] END C=0.1, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.834) f1_weighted: (test=0.986) total time=110.8min\n",
      "[CV 1/1; 13/40] START C=1, gamma=auto, kernel=linear............................\n",
      "[CV 1/1; 2/40] END C=0.1, gamma=scale, kernel=rbf; balanced_accuracy: (test=0.833) f1_weighted: (test=0.986) total time=131.3min\n",
      "[CV 1/1; 14/40] START C=1, gamma=auto, kernel=rbf...............................\n",
      "[CV 1/1; 13/40] END C=1, gamma=auto, kernel=linear; balanced_accuracy: (test=0.943) f1_weighted: (test=0.989) total time=32.3min\n",
      "[CV 1/1; 15/40] START C=1, gamma=auto, kernel=poly..............................\n",
      "[CV 1/1; 14/40] END C=1, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.959) f1_weighted: (test=0.995) total time=30.9min\n",
      "[CV 1/1; 16/40] START C=1, gamma=auto, kernel=sigmoid...........................\n",
      "[CV 1/1; 4/40] END C=0.1, gamma=scale, kernel=sigmoid; balanced_accuracy: (test=0.656) f1_weighted: (test=0.897) total time=166.7min\n",
      "[CV 1/1; 17/40] START C=10, gamma=scale, kernel=linear..........................\n",
      "[CV 1/1; 12/40] END C=1, gamma=scale, kernel=sigmoid; balanced_accuracy: (test=0.705) f1_weighted: (test=0.880) total time=117.1min\n",
      "[CV 1/1; 18/40] START C=10, gamma=scale, kernel=rbf.............................\n",
      "[CV 1/1; 18/40] END C=10, gamma=scale, kernel=rbf; balanced_accuracy: (test=0.971) f1_weighted: (test=0.998) total time= 8.2min\n",
      "[CV 1/1; 19/40] START C=10, gamma=scale, kernel=poly............................\n",
      "[CV 1/1; 8/40] END C=0.1, gamma=auto, kernel=sigmoid; balanced_accuracy: (test=0.652) f1_weighted: (test=0.896) total time=200.3min\n",
      "[CV 1/1; 20/40] START C=10, gamma=scale, kernel=sigmoid.........................\n",
      "[CV 1/1; 11/40] END C=1, gamma=scale, kernel=poly; balanced_accuracy: (test=0.772) f1_weighted: (test=0.932) total time=181.2min\n",
      "[CV 1/1; 21/40] START C=10, gamma=auto, kernel=linear...........................\n",
      "[CV 1/1; 16/40] END C=1, gamma=auto, kernel=sigmoid; balanced_accuracy: (test=0.697) f1_weighted: (test=0.880) total time=94.2min\n",
      "[CV 1/1; 22/40] START C=10, gamma=auto, kernel=rbf..............................\n",
      "[CV 1/1; 22/40] END C=10, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.971) f1_weighted: (test=0.998) total time=11.0min\n",
      "[CV 1/1; 23/40] START C=10, gamma=auto, kernel=poly.............................\n",
      "[CV 1/1; 15/40] END C=1, gamma=auto, kernel=poly; balanced_accuracy: (test=0.778) f1_weighted: (test=0.938) total time=134.1min\n",
      "[CV 1/1; 24/40] START C=10, gamma=auto, kernel=sigmoid..........................\n",
      "[CV 1/1; 17/40] END C=10, gamma=scale, kernel=linear; balanced_accuracy: (test=0.949) f1_weighted: (test=0.989) total time=121.4min\n",
      "[CV 1/1; 25/40] START C=100, gamma=scale, kernel=linear.........................\n",
      "[CV 1/1; 7/40] END C=0.1, gamma=auto, kernel=poly; balanced_accuracy: (test=0.679) f1_weighted: (test=0.795) total time=295.3min\n",
      "[CV 1/1; 26/40] START C=100, gamma=scale, kernel=rbf............................\n",
      "[CV 1/1; 26/40] END C=100, gamma=scale, kernel=rbf; balanced_accuracy: (test=0.984) f1_weighted: (test=0.999) total time= 3.5min\n",
      "[CV 1/1; 27/40] START C=100, gamma=scale, kernel=poly...........................\n",
      "[CV 1/1; 19/40] END C=10, gamma=scale, kernel=poly; balanced_accuracy: (test=0.924) f1_weighted: (test=0.985) total time=110.2min\n",
      "[CV 1/1; 28/40] START C=100, gamma=scale, kernel=sigmoid........................\n",
      "[CV 1/1; 20/40] END C=10, gamma=scale, kernel=sigmoid; balanced_accuracy: (test=0.720) f1_weighted: (test=0.878) total time=101.3min\n",
      "[CV 1/1; 29/40] START C=100, gamma=auto, kernel=linear..........................\n",
      "[CV 1/1; 3/40] END C=0.1, gamma=scale, kernel=poly; balanced_accuracy: (test=0.665) f1_weighted: (test=0.783) total time=323.7min\n",
      "[CV 1/1; 30/40] START C=100, gamma=auto, kernel=rbf.............................\n",
      "[CV 1/1; 30/40] END C=100, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.985) f1_weighted: (test=0.999) total time= 3.4min\n",
      "[CV 1/1; 31/40] START C=100, gamma=auto, kernel=poly............................\n",
      "[CV 1/1; 27/40] END C=100, gamma=scale, kernel=poly; balanced_accuracy: (test=0.949) f1_weighted: (test=0.995) total time=36.8min\n",
      "[CV 1/1; 32/40] START C=100, gamma=auto, kernel=sigmoid.........................\n",
      "[CV 1/1; 31/40] END C=100, gamma=auto, kernel=poly; balanced_accuracy: (test=0.965) f1_weighted: (test=0.996) total time=23.5min\n",
      "[CV 1/1; 33/40] START C=1000, gamma=scale, kernel=linear........................\n",
      "[CV 1/1; 23/40] END C=10, gamma=auto, kernel=poly; balanced_accuracy: (test=0.925) f1_weighted: (test=0.986) total time=83.6min\n",
      "[CV 1/1; 34/40] START C=1000, gamma=scale, kernel=rbf...........................\n",
      "[CV 1/1; 34/40] END C=1000, gamma=scale, kernel=rbf; balanced_accuracy: (test=0.989) f1_weighted: (test=0.999) total time= 2.9min\n",
      "[CV 1/1; 35/40] START C=1000, gamma=scale, kernel=poly..........................\n",
      "[CV 1/1; 24/40] END C=10, gamma=auto, kernel=sigmoid; balanced_accuracy: (test=0.690) f1_weighted: (test=0.874) total time=80.8min\n",
      "[CV 1/1; 36/40] START C=1000, gamma=scale, kernel=sigmoid.......................\n",
      "[CV 1/1; 21/40] END C=10, gamma=auto, kernel=linear; balanced_accuracy: (test=0.949) f1_weighted: (test=0.989) total time=125.4min\n",
      "[CV 1/1; 37/40] START C=1000, gamma=auto, kernel=linear.........................\n",
      "[CV 1/1; 28/40] END C=100, gamma=scale, kernel=sigmoid; balanced_accuracy: (test=0.715) f1_weighted: (test=0.874) total time=81.2min\n",
      "[CV 1/1; 38/40] START C=1000, gamma=auto, kernel=rbf............................\n",
      "[CV 1/1; 38/40] END C=1000, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.991) f1_weighted: (test=1.000) total time= 3.2min\n",
      "[CV 1/1; 39/40] START C=1000, gamma=auto, kernel=poly...........................\n",
      "[CV 1/1; 35/40] END C=1000, gamma=scale, kernel=poly; balanced_accuracy: (test=0.980) f1_weighted: (test=0.999) total time=33.5min\n",
      "[CV 1/1; 40/40] START C=1000, gamma=auto, kernel=sigmoid........................\n",
      "[CV 1/1; 32/40] END C=100, gamma=auto, kernel=sigmoid; balanced_accuracy: (test=0.692) f1_weighted: (test=0.870) total time=88.7min\n",
      "[CV 1/1; 36/40] END C=1000, gamma=scale, kernel=sigmoid; balanced_accuracy: (test=0.720) f1_weighted: (test=0.879) total time=78.5min\n",
      "[CV 1/1; 40/40] END C=1000, gamma=auto, kernel=sigmoid; balanced_accuracy: (test=0.701) f1_weighted: (test=0.877) total time=69.2min\n",
      "[CV 1/1; 39/40] END C=1000, gamma=auto, kernel=poly; balanced_accuracy: (test=0.980) f1_weighted: (test=0.999) total time=451.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m scoring \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(), param_grid, cv\u001b[38;5;241m=\u001b[39mps, scoring\u001b[38;5;241m=\u001b[39mscoring, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyper: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid\u001b[38;5;241m.\u001b[39mbest_estimator_)\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    966\u001b[0m         )\n\u001b[1;32m    967\u001b[0m     )\n\u001b[0;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# X = pca.transform(X)\n",
    "\n",
    "# lda = LinearDiscriminantAnalysis()\n",
    "# lda.fit(X_train, y_train)\n",
    "# lda.transform(X)\n",
    "\n",
    "\n",
    "# SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 2 e 3\n",
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "# 4\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "# 5\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "# 6\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "print(df.select_dtypes(include=['object']).shape)\n",
    "\n",
    "# 7\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "# 8\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=seed)\n",
    "# val_idx, test_idx = train_test_split(val_idx, test_size=0.5, stratify=y[val_idx], random_state=seed)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "# fold[test_idx] = 1\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "# X_test = X[test_idx,:]\n",
    "# y_test = y[test_idx]\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# pca = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# X = pca.transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "lda.transform(X)\n",
    "\n",
    "\n",
    "# SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "grid.fit(X, y)\n",
    "print(\"---------------------------------\")\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV 2/2; 4/10] START C=1, penalty=l2............................................\n",
      "[CV 1/2; 3/10] START C=1, penalty=l1............................................\n",
      "[CV 1/2; 1/10] START C=0.1, penalty=l1..........................................\n",
      "[CV 2/2; 3/10] START C=1, penalty=l1............................................[CV 2/2; 2/10] START C=0.1, penalty=l2..........................................\n",
      "\n",
      "[CV 2/2; 1/10] START C=0.1, penalty=l1..........................................[CV 1/2; 4/10] START C=1, penalty=l2............................................\n",
      "\n",
      "[CV 1/2; 2/10] START C=0.1, penalty=l2..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 1/10] END ...........C=0.1, penalty=l1;, score=0.649 total time=59.8min\n",
      "[CV 1/2; 5/10] START C=10, penalty=l1...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 1/10] END ...........C=0.1, penalty=l1;, score=0.650 total time=62.7min\n",
      "[CV 2/2; 5/10] START C=10, penalty=l1...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 3/10] END .............C=1, penalty=l1;, score=0.666 total time=72.4min\n",
      "[CV 1/2; 6/10] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 3/10] END .............C=1, penalty=l1;, score=0.661 total time=76.0min\n",
      "[CV 2/2; 6/10] START C=10, penalty=l2...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 2/10] END ...........C=0.1, penalty=l2;, score=0.653 total time=81.6min\n",
      "[CV 1/2; 7/10] START C=100, penalty=l1..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 2/10] END ..........C=0.1, penalty=l2;, score=0.653 total time=112.3min\n",
      "[CV 2/2; 7/10] START C=100, penalty=l1..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 5/10] END ............C=10, penalty=l1;, score=0.666 total time=99.2min\n",
      "[CV 1/2; 8/10] START C=100, penalty=l2..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 5/10] END ............C=10, penalty=l1;, score=0.661 total time=99.0min\n",
      "[CV 2/2; 8/10] START C=100, penalty=l2..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 7/10] END ..........C=100, penalty=l1;, score=0.666 total time=105.0min\n",
      "[CV 1/2; 9/10] START C=1000, penalty=l1.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 7/10] END ..........C=100, penalty=l1;, score=0.661 total time=114.5min\n",
      "[CV 2/2; 9/10] START C=1000, penalty=l1.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 4/10] END ............C=1, penalty=l2;, score=0.670 total time=285.0min\n",
      "[CV 1/2; 10/10] START C=1000, penalty=l2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 9/10] END .........C=1000, penalty=l1;, score=0.666 total time=107.7min\n",
      "[CV 2/2; 10/10] START C=1000, penalty=l2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 9/10] END .........C=1000, penalty=l1;, score=0.662 total time=102.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 4/10] END ............C=1, penalty=l2;, score=0.668 total time=343.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 6/10] END ...........C=10, penalty=l2;, score=0.683 total time=273.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 6/10] END ...........C=10, penalty=l2;, score=0.688 total time=278.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 8/10] END ..........C=100, penalty=l2;, score=0.698 total time=195.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 8/10] END ..........C=100, penalty=l2;, score=0.700 total time=195.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 10/10] END .........C=1000, penalty=l2;, score=0.723 total time=80.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 10/10] END .........C=1000, penalty=l2;, score=0.719 total time=72.9min\n",
      "Best hyper:  LinearSVC(C=1000, random_state=42)\n",
      "Best score:  0.7207091302697002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10, 100, 1000],  \n",
    "}  \n",
    "\n",
    "grid = GridSearchCV(svm.LinearSVC(random_state=seed), param_grid, verbose=10, cv=ps, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "file = open(\"svm.save\", \"wb\")\n",
    "pickle.dump(grid.best_estimator_, file)\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2; 2/6] START C=10000, penalty=l2.........................................[CV 2/2; 2/6] START C=10000, penalty=l2.........................................\n",
      "[CV 1/2; 4/6] START C=100000, penalty=l2........................................\n",
      "[CV 2/2; 1/6] START C=10000, penalty=l1.........................................\n",
      "[CV 1/2; 3/6] START C=100000, penalty=l1........................................\n",
      "[CV 1/2; 1/6] START C=10000, penalty=l1.........................................\n",
      "[CV 2/2; 4/6] START C=100000, penalty=l2........................................\n",
      "[CV 2/2; 3/6] START C=100000, penalty=l1........................................\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m100000\u001b[39m, \u001b[38;5;241m1000000\u001b[39m],  \n\u001b[1;32m      4\u001b[0m }  \n\u001b[1;32m      6\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(svm\u001b[38;5;241m.\u001b[39mLinearSVC(random_state\u001b[38;5;241m=\u001b[39mseed), param_grid, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39mps, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_.save\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(grid\u001b[38;5;241m.\u001b[39mbest_estimator_, file)\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    966\u001b[0m         )\n\u001b[1;32m    967\u001b[0m     )\n\u001b[0;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/data-analytics/.env/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [10000, 100000, 1000000],  \n",
    "}  \n",
    "\n",
    "grid = GridSearchCV(svm.LinearSVC(random_state=seed), param_grid, verbose=10, cv=ps, scoring='balanced_accuracy', n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "file = open(\"svm_.save\", \"wb\")\n",
    "pickle.dump(grid.best_estimator_, file)\n",
    "print(\"Best hyper: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
