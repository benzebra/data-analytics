{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "seed = 42\n",
    "\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "\n",
    "#Prepare train data\n",
    "df1 = pd.read_csv(FILENAME, encoding='ISO-8859-1', sep=\",\", low_memory=False)\n",
    "# print(\"EX1) #Righe: \" + str(df1.shape[0])+ \" #Colonne: \"+str(df1.shape[1]))\n",
    "\n",
    "# print(df1.nunique())\n",
    "# print(df1.isna().sum())\n",
    "\n",
    "# print(df1.shape)\n",
    "df1 = df1.dropna()\n",
    "# print(df1.shape)\n",
    "\n",
    "\n",
    "y = df1[\"type\"]\n",
    "X = df1.drop(columns=[\"type\", \"label\"])\n",
    "\n",
    "err_arr = X.loc[X[\"src_bytes\"] == \"0.0.0.0\"]\n",
    "X = X.drop(index=err_arr.index)\n",
    "y = y.drop(index=err_arr.index)\n",
    "X.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "for feature in [\"dns_AA\",\"dns_RD\",\"dns_RA\",\"dns_rejected\",\"ssl_version\",\"ssl_cipher\",\"ssl_resumed\",\"ssl_established\",\"ssl_subject\",\"ssl_issuer\",\"http_trans_depth\",\"http_method\",\"http_uri\",\"http_referrer\",\"http_version\",\"http_request_body_len\",\"http_response_body_len\",\"http_status_code\",\"http_user_agent\",\"http_orig_mime_types\",\"http_resp_mime_types\",\"weird_name\",\"weird_addl\",\"weird_notice\"]:\n",
    "    # print(f\"Feature: {feature}\")    \n",
    "    feature_index = np.where(df1.columns == feature)[0][0]\n",
    "    elements, counts = np.unique(X[:, feature_index], return_counts=True)\n",
    "\n",
    "    # for element, count in zip(elements, counts):\n",
    "    #     print(f\"    Element: {element}, Count: {count}\")\n",
    "\n",
    "\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "oe.fit(X)\n",
    "X = oe.transform(X)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "\n",
    "# variances = np.var(X, axis=0)\n",
    "# features = df1.columns\n",
    "# for i, variance in enumerate(variances):\n",
    "#     print(f\"{features[i]} \\t\\t: Variance = {variance}\")\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(0.01)\n",
    "X_mod = selector.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Modified shape: {X_mod.shape}\")\n",
    "\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(X_mod.shape[0]), test_size=0.2, stratify=y, random_state=seed)\n",
    "test_idx, val_idx = train_test_split(test_idx, test_size=0.5, stratify=y[test_idx], random_state=seed)\n",
    "\n",
    "y_test = y[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "X_test_mod = X_mod[test_idx,:]\n",
    "X_train_mod = X_mod[train_idx,:]\n",
    "X_val_mod = X_mod[val_idx,:]\n",
    "\n",
    "X_test = X[test_idx,:]\n",
    "X_train = X[train_idx,:]\n",
    "X_val = X[val_idx,:]\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(X_train_mod.shape, X_test_mod.shape, X_val_mod.shape)\n",
    "print(len(y_train), len(y_test), len(y_val))\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import decomposition\n",
    "\n",
    "## Scaling (treshold)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_mod)\n",
    "X_train_mod = scaler.transform(X_train_mod)\n",
    "X_test_mod = scaler.transform(X_test_mod)\n",
    "X_val_mod = scaler.transform(X_val_mod)\n",
    "\n",
    "## Scaling (no treshold)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(X_train_mod.shape, X_test_mod.shape, X_val_mod.shape)\n",
    "\n",
    "\n",
    "## PCA (treshold)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_train_mod)\n",
    "X_train_mod_pca = pca.transform(X_train_mod)\n",
    "X_test_mod_pca = pca.transform(X_test_mod)\n",
    "X_val_mod_pca = pca.transform(X_val_mod)\n",
    "\n",
    "## PCA (no treshold)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(X_train_pca.shape, X_test_pca.shape, X_val_pca.shape)\n",
    "print(X_train_mod_pca.shape, X_test_mod_pca.shape, X_val_mod_pca.shape)\n",
    "\n",
    "\n",
    "## LDA (treshold)\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "lda.fit(X_train_mod, y_train)\n",
    "X_train_mod_lda = lda.transform(X_train_mod)\n",
    "X_test_mod_lda = lda.transform(X_test_mod)\n",
    "X_val_mod_lda = lda.transform(X_val_mod)\n",
    "\n",
    "## LDA (no treshold)\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "lda.fit(X_train, y_train)\n",
    "X_train_lda = lda.transform(X_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "X_val_lda = lda.transform(X_val)\n",
    "\n",
    "X_train_std = X_train\n",
    "X_test_std = X_test\n",
    "X_val_std = X_val\n",
    "\n",
    "print(X_train_lda.shape, X_test_lda.shape, X_val_lda.shape)\n",
    "print(X_train_mod_lda.shape, X_test_mod_lda.shape, X_val_mod_lda.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
