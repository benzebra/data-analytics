{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "seed = 42\n",
    "\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "\n",
    "#Prepare train data\n",
    "df1 = pd.read_csv(FILENAME, encoding='ISO-8859-1', sep=\",\", low_memory=False)\n",
    "# print(\"EX1) #Righe: \" + str(df1.shape[0])+ \" #Colonne: \"+str(df1.shape[1]))\n",
    "\n",
    "# print(df1.nunique())\n",
    "# print(df1.isna().sum())\n",
    "\n",
    "# print(df1.shape)\n",
    "df1 = df1.dropna()\n",
    "# print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"type\"]\n",
    "X = df1.drop(columns=[\"type\", \"label\"])\n",
    "\n",
    "err_arr = X.loc[X[\"src_bytes\"] == \"0.0.0.0\"]\n",
    "X = X.drop(index=err_arr.index)\n",
    "y = y.drop(index=err_arr.index)\n",
    "X.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "for feature in [\"dns_AA\",\"dns_RD\",\"dns_RA\",\"dns_rejected\",\"ssl_version\",\"ssl_cipher\",\"ssl_resumed\",\"ssl_established\",\"ssl_subject\",\"ssl_issuer\",\"http_trans_depth\",\"http_method\",\"http_uri\",\"http_referrer\",\"http_version\",\"http_request_body_len\",\"http_response_body_len\",\"http_status_code\",\"http_user_agent\",\"http_orig_mime_types\",\"http_resp_mime_types\",\"weird_name\",\"weird_addl\",\"weird_notice\"]:\n",
    "    # print(f\"Feature: {feature}\")    \n",
    "    feature_index = np.where(df1.columns == feature)[0][0]\n",
    "    elements, counts = np.unique(X[:, feature_index], return_counts=True)\n",
    "\n",
    "    # for element, count in zip(elements, counts):\n",
    "    #     print(f\"    Element: {element}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oe = preprocessing.OrdinalEncoder()\n",
    "# oe.fit(X)\n",
    "# X = oe.transform(X)\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(y)\n",
    "# y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1554350584 296.0 53972 ... 0.0 0.0 0.0]\n",
      " [1556087112 302.0 37513 ... 0.0 0.0 0.0]\n",
      " [1556140763 296.0 2077 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [1556547123 311.0 54730 ... 0.0 0.0 0.0]\n",
      " [1556547464 314.0 59846 ... 0.0 0.0 0.0]\n",
      " [1556547114 311.0 56698 ... 0.0 0.0 0.0]]\n"
     ]
    }
   ],
   "source": [
    "## FOR MINMAX SCALING\n",
    "# oe = preprocessing.OrdinalEncoder()\n",
    "# oe.fit(X)\n",
    "# X = oe.transform(X)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "# Check if columns are numerical, if not use OrdinalEncoder\n",
    "for col in df1.columns:\n",
    "    if df1[col].dtype == 'object':\n",
    "        col_index = df1.columns.get_loc(col)\n",
    "        if col_index < X.shape[1]:  # Ensure the column index is within bounds\n",
    "            oe = preprocessing.OrdinalEncoder()\n",
    "            X[:, col_index] = oe.fit_transform(X[:, col_index].reshape(-1, 1)).flatten()\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts \t\t: Variance = 1783833117.1326857\n",
      "src_ip \t\t: Variance = 284.11687981463507\n",
      "src_port \t\t: Variance = 226183441.1094727\n",
      "dst_ip \t\t: Variance = 18069.481632403946\n",
      "dst_port \t\t: Variance = 112729606.3787938\n",
      "proto \t\t: Variance = 0.07609999553869298\n",
      "service \t\t: Variance = 17.47203143096537\n",
      "duration \t\t: Variance = 3668014251.625104\n",
      "src_bytes \t\t: Variance = 1243377.3513259336\n",
      "dst_bytes \t\t: Variance = 275244.427664733\n",
      "conn_state \t\t: Variance = 12.47918490190582\n",
      "missed_bytes \t\t: Variance = 2172.8186935295867\n",
      "src_pkts \t\t: Variance = 138.1312245942286\n",
      "src_ip_bytes \t\t: Variance = 369389.06178173196\n",
      "dst_pkts \t\t: Variance = 8.776803127539445\n",
      "dst_ip_bytes \t\t: Variance = 585861.2144607559\n",
      "dns_query \t\t: Variance = 208822.20217437387\n",
      "dns_qclass \t\t: Variance = 0.06832388472089732\n",
      "dns_qtype \t\t: Variance = 0.26119829202000905\n",
      "dns_rcode \t\t: Variance = 0.12338129665094301\n",
      "dns_AA \t\t: Variance = 0.07302113656078127\n",
      "dns_RD \t\t: Variance = 0.259392226367049\n",
      "dns_RA \t\t: Variance = 0.16315153361398274\n",
      "dns_rejected \t\t: Variance = 0.16123279942145347\n",
      "ssl_version \t\t: Variance = 0.0014492264327511343\n",
      "ssl_cipher \t\t: Variance = 0.026862950868848216\n",
      "ssl_resumed \t\t: Variance = 0.0011721128906846904\n",
      "ssl_established \t\t: Variance = 0.004256276889943761\n",
      "ssl_subject \t\t: Variance = 0.0010459611805872892\n",
      "ssl_issuer \t\t: Variance = 0.0010459611805872892\n",
      "http_trans_depth \t\t: Variance = 0.0011947124091692366\n",
      "http_method \t\t: Variance = 0.0031263617596692123\n",
      "http_uri \t\t: Variance = 0.19006966007952983\n",
      "http_referrer \t\t: Variance = 0.0\n",
      "http_version \t\t: Variance = 0.0011704581260124644\n",
      "http_request_body_len \t\t: Variance = 0.0020177261157572337\n",
      "http_response_body_len \t\t: Variance = 0.07437027379846528\n",
      "http_status_code \t\t: Variance = 0.009843938562125329\n",
      "http_user_agent \t\t: Variance = 3.9792747728976843\n",
      "http_orig_mime_types \t\t: Variance = 0.00039705385572336074\n",
      "http_resp_mime_types \t\t: Variance = 0.0036326394155508086\n",
      "weird_name \t\t: Variance = 0.0038247503828618356\n",
      "weird_addl \t\t: Variance = 0.00017341717226810623\n",
      "weird_notice \t\t: Variance = 0.0001345074894730269\n"
     ]
    }
   ],
   "source": [
    "# variances = np.var(X, axis=0)\n",
    "# features = df1.columns\n",
    "# for i, variance in enumerate(variances):\n",
    "#     print(f\"{features[i]} \\t\\t: Variance = {variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (616983, 44)\n",
      "Modified shape: (616983, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(0.01)\n",
    "X_mod = selector.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Modified shape: {X_mod.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493586, 44) (61698, 44) (61699, 44)\n",
      "(493586, 30) (61698, 30) (61699, 30)\n",
      "493586 61698 61699\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(X_mod.shape[0]), test_size=0.2, stratify=y, random_state=seed)\n",
    "test_idx, val_idx = train_test_split(test_idx, test_size=0.5, stratify=y[test_idx], random_state=seed)\n",
    "\n",
    "y_test = y[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "X_test_mod = X_mod[test_idx,:]\n",
    "X_train_mod = X_mod[train_idx,:]\n",
    "X_val_mod = X_mod[val_idx,:]\n",
    "\n",
    "X_test = X[test_idx,:]\n",
    "X_train = X[train_idx,:]\n",
    "X_val = X[val_idx,:]\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(X_train_mod.shape, X_test_mod.shape, X_val_mod.shape)\n",
    "print(len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493586, 44) (61698, 44) (61699, 44)\n",
      "(493586, 28) (61698, 28) (61699, 28)\n",
      "(493586, 44) (61698, 44) (61699, 44)\n",
      "(493586, 28) (61698, 28) (61699, 28)\n",
      "(493586, 9) (61698, 9) (61699, 9)\n",
      "(493586, 9) (61698, 9) (61699, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import decomposition\n",
    "\n",
    "## Scaling (treshold)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_mod)\n",
    "X_train_mod = scaler.transform(X_train_mod)\n",
    "X_test_mod = scaler.transform(X_test_mod)\n",
    "X_val_mod = scaler.transform(X_val_mod)\n",
    "\n",
    "## Scaling (no treshold)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "print(X_train_mod.shape, X_test_mod.shape, X_val_mod.shape)\n",
    "\n",
    "\n",
    "## PCA (treshold)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_train_mod)\n",
    "X_train_mod_pca = pca.transform(X_train_mod)\n",
    "X_test_mod_pca = pca.transform(X_test_mod)\n",
    "X_val_mod_pca = pca.transform(X_val_mod)\n",
    "\n",
    "## PCA (no treshold)\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "print(X_train_pca.shape, X_test_pca.shape, X_val_pca.shape)\n",
    "print(X_train_mod_pca.shape, X_test_mod_pca.shape, X_val_mod_pca.shape)\n",
    "\n",
    "\n",
    "## LDA (treshold)\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "lda.fit(X_train_mod, y_train)\n",
    "X_train_mod_lda = lda.transform(X_train_mod)\n",
    "X_test_mod_lda = lda.transform(X_test_mod)\n",
    "X_val_mod_lda = lda.transform(X_val_mod)\n",
    "\n",
    "## LDA (no treshold)\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "lda.fit(X_train, y_train)\n",
    "X_train_lda = lda.transform(X_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "X_val_lda = lda.transform(X_val)\n",
    "\n",
    "print(X_train_lda.shape, X_test_lda.shape, X_val_lda.shape)\n",
    "print(X_train_mod_lda.shape, X_test_mod_lda.shape, X_val_mod_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "scaler_mod = MinMaxScaler()\n",
    "X_train_mod = scaler.fit_transform(X_train_mod)\n",
    "X_test_mod = scaler.transform(X_test_mod)\n",
    "X_val_mod = scaler.transform(X_val_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485234529482317\n"
     ]
    }
   ],
   "source": [
    "## PCA, treshold\n",
    "clf_mod_pca = svm.LinearSVC(random_state=seed)\n",
    "clf_mod_pca.fit(X_train_mod_pca, y_train)\n",
    "y_mod_pca_pred = clf_mod_pca.predict(X_test_mod_pca)\n",
    "\n",
    "print(accuracy_score(y_test, y_mod_pca_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     1     0     0     0     0     0     0     0     0]\n",
      " [    0 17651   129   111     0   296    53     0     0     9]\n",
      " [    0    25  5342     6     0    70     0     0     5     0]\n",
      " [    0    97    16  1219     0    13     4     0     9     0]\n",
      " [    0     9     1     0    34     2     1     0     0    15]\n",
      " [   23   104   168    12    13  1233    21    55   417    20]\n",
      " [    0  1103     1     0     0    16  4021     0     0    15]\n",
      " [    5     4     0     0     0     7     1    71     0     8]\n",
      " [    0    12   139    36     0    31     2     0 21201     0]\n",
      " [    0    76     0     0     0     7   108     1     0  6135]]\n",
      "0.9468873077359439\n",
      "0.9453073456296222\n",
      "0.9462369773053101\n",
      "0.9468873077359439\n",
      "0.8518055415975313\n",
      "0.865204355626517\n",
      "0.846878589763229\n",
      "0.846878589763229\n"
     ]
    }
   ],
   "source": [
    "clf = clf_mod_pca\n",
    "x = X_val_mod_pca\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1516\n",
      "           1       0.93      0.97      0.95     18249\n",
      "           2       0.92      0.98      0.95      5448\n",
      "           3       0.88      0.90      0.89      1358\n",
      "           4       0.72      0.55      0.62        62\n",
      "           5       0.74      0.60      0.66      2066\n",
      "           6       0.95      0.78      0.86      5156\n",
      "           7       0.56      0.74      0.64        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.99      0.97      0.98      6327\n",
      "\n",
      "    accuracy                           0.95     61699\n",
      "   macro avg       0.87      0.85      0.85     61699\n",
      "weighted avg       0.95      0.95      0.95     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486044928522804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## PCA, no treshold\n",
    "clf_pca = svm.LinearSVC(random_state=seed)\n",
    "clf_pca.fit(X_train_pca, y_train)\n",
    "y_pca_pred = clf_pca.predict(X_test_pca)\n",
    "\n",
    "print(accuracy_score(y_test, y_pca_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     1     0     0     0     0     0     0     0     0]\n",
      " [    0 17649   129   110     0   297    55     0     0     9]\n",
      " [    0    25  5342     6     0    70     0     0     5     0]\n",
      " [    0    97    16  1220     0    12     4     0     9     0]\n",
      " [    0     9     1     0    34     2     1     0     0    15]\n",
      " [   24   104   168    12    13  1233    21    53   418    20]\n",
      " [    0  1101     1     0     0    16  4023     0     0    15]\n",
      " [    5     4     0     0     0     7     1    71     0     8]\n",
      " [    1    12   138    36     0    31     2     0 21201     0]\n",
      " [    0    76     0     0     0     7   106     1     0  6137]]\n",
      "0.9469359308902899\n",
      "0.9453513294773028\n",
      "0.9462623864201881\n",
      "0.9469359308902899\n",
      "0.8524362644010278\n",
      "0.866066772626581\n",
      "0.8470116682785325\n",
      "0.8470116682785325\n"
     ]
    }
   ],
   "source": [
    "clf = clf_pca\n",
    "x = X_val_pca\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1516\n",
      "           1       0.93      0.97      0.95     18249\n",
      "           2       0.92      0.98      0.95      5448\n",
      "           3       0.88      0.90      0.89      1358\n",
      "           4       0.72      0.55      0.62        62\n",
      "           5       0.74      0.60      0.66      2066\n",
      "           6       0.95      0.78      0.86      5156\n",
      "           7       0.57      0.74      0.64        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.99      0.97      0.98      6327\n",
      "\n",
      "    accuracy                           0.95     61699\n",
      "   macro avg       0.87      0.85      0.85     61699\n",
      "weighted avg       0.95      0.95      0.95     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9252812084670492\n"
     ]
    }
   ],
   "source": [
    "## LDA, treshold\n",
    "clf_mod_lda = svm.LinearSVC(random_state=seed)\n",
    "clf_mod_lda.fit(X_train_mod_lda, y_train)\n",
    "y_mod_lda_pred = clf_mod_lda.predict(X_test_mod_lda)\n",
    "\n",
    "print(accuracy_score(y_test, y_mod_lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     0     0     0     0     0     1     0     0     0]\n",
      " [    0 17606   145    68     0   290   137     0     0     3]\n",
      " [    0    23  5287    33     0    70     0     0    35     0]\n",
      " [    0   125    30  1163     0     4    14     0    22     0]\n",
      " [    1    10     1     0    19     0     3     0     0    28]\n",
      " [   58    91   201    64     9   995   123    55   388    82]\n",
      " [    0  1741     7     1     0    97  3228     0     0    82]\n",
      " [   43     0     0     0     0     8    34     1     0    10]\n",
      " [    0    18   185    46     0    27     0     0 21145     0]\n",
      " [    1   130     0     0     0    19   120     0     0  6057]]\n",
      "0.9240992560657385\n",
      "0.9195278108733755\n",
      "0.9207860797473512\n",
      "0.9240992560657385\n",
      "0.7349796573159308\n",
      "0.7760695624659854\n",
      "0.7159943075106613\n",
      "0.7159943075106613\n"
     ]
    }
   ],
   "source": [
    "clf = clf_mod_lda\n",
    "x = X_val_mod_lda\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1516\n",
      "           1       0.89      0.96      0.93     18249\n",
      "           2       0.90      0.97      0.94      5448\n",
      "           3       0.85      0.86      0.85      1358\n",
      "           4       0.68      0.31      0.42        62\n",
      "           5       0.66      0.48      0.56      2066\n",
      "           6       0.88      0.63      0.73      5156\n",
      "           7       0.02      0.01      0.01        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.97      0.96      0.96      6327\n",
      "\n",
      "    accuracy                           0.92     61699\n",
      "   macro avg       0.78      0.72      0.73     61699\n",
      "weighted avg       0.92      0.92      0.92     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9254757042367662\n"
     ]
    }
   ],
   "source": [
    "## LDA, no treshold\n",
    "clf_lda = svm.LinearSVC(random_state=seed)\n",
    "clf_lda.fit(X_train_lda, y_train)\n",
    "y_lda_pred = clf_lda.predict(X_test_lda)\n",
    "\n",
    "print(accuracy_score(y_test, y_lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     0     0     0     0     0     1     0     0     0]\n",
      " [    0 17605   144    68     0   290   139     0     0     3]\n",
      " [    0    23  5286    34     0    70     0     0    35     0]\n",
      " [    0   125    30  1163     0     4    14     0    22     0]\n",
      " [    0    11     1     0    19     0     3     0     0    28]\n",
      " [   58    89   200    63     9   999   123    54   388    83]\n",
      " [    0  1737     7     1     0    96  3233     0     0    82]\n",
      " [   44     0     0     0     0     8    33     1     0    10]\n",
      " [    0    18   185    47     0    27     0     0 21144     0]\n",
      " [    1   131     0     0     0    19   117     0     0  6059]]\n",
      "0.9242289178106614\n",
      "0.9196819299496829\n",
      "0.9209340446538379\n",
      "0.9242289178106614\n",
      "0.7352431468408593\n",
      "0.7762707694766096\n",
      "0.7162879998813347\n",
      "0.7162879998813347\n"
     ]
    }
   ],
   "source": [
    "clf = clf_lda\n",
    "x = X_val_lda\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1516\n",
      "           1       0.89      0.96      0.93     18249\n",
      "           2       0.90      0.97      0.94      5448\n",
      "           3       0.85      0.86      0.85      1358\n",
      "           4       0.68      0.31      0.42        62\n",
      "           5       0.66      0.48      0.56      2066\n",
      "           6       0.88      0.63      0.73      5156\n",
      "           7       0.02      0.01      0.01        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.97      0.96      0.96      6327\n",
      "\n",
      "    accuracy                           0.92     61699\n",
      "   macro avg       0.78      0.72      0.74     61699\n",
      "weighted avg       0.92      0.92      0.92     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no preprocess, treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485396609290414\n"
     ]
    }
   ],
   "source": [
    "## no prep, treshold\n",
    "clf_mod = svm.LinearSVC(random_state=seed)\n",
    "clf_mod.fit(X_train_mod, y_train)\n",
    "y_mod_pred = clf_mod.predict(X_test_mod)\n",
    "\n",
    "print(accuracy_score(y_test, y_mod_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     1     0     0     0     0     0     0     0     0]\n",
      " [    0 17651   129   111     0   296    53     0     0     9]\n",
      " [    0    25  5342     6     0    70     0     0     5     0]\n",
      " [    0    97    16  1219     0    13     4     0     9     0]\n",
      " [    0     9     1     0    34     2     1     0     0    15]\n",
      " [   23   104   168    12    13  1233    21    55   417    20]\n",
      " [    0  1104     1     0     0    16  4020     0     0    15]\n",
      " [    5     4     0     0     0     7     1    71     0     8]\n",
      " [    0    12   139    36     0    31     2     0 21201     0]\n",
      " [    0    76     0     0     0     7   108     1     0  6135]]\n",
      "0.9468711000178285\n",
      "0.9452896689446899\n",
      "0.9462217446436155\n",
      "0.9468711000178285\n",
      "0.8517908213108194\n",
      "0.8651984366069223\n",
      "0.8468591948834774\n",
      "0.8468591948834774\n"
     ]
    }
   ],
   "source": [
    "clf = clf_mod\n",
    "x = X_val_mod\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1516\n",
      "           1       0.92      0.97      0.95     18249\n",
      "           2       0.92      0.98      0.95      5448\n",
      "           3       0.88      0.90      0.89      1358\n",
      "           4       0.72      0.55      0.62        62\n",
      "           5       0.74      0.60      0.66      2066\n",
      "           6       0.95      0.78      0.86      5156\n",
      "           7       0.56      0.74      0.64        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.99      0.97      0.98      6327\n",
      "\n",
      "    accuracy                           0.95     61699\n",
      "   macro avg       0.87      0.85      0.85     61699\n",
      "weighted avg       0.95      0.95      0.95     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no preprocess, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485558689098512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/svm/_base.py:1243: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## no prep, no treshold\n",
    "clf = svm.LinearSVC(random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     0     0     0     0     0     1     0     0     0]\n",
      " [    0 17649   129   111     0   297    55     0     0     8]\n",
      " [    0    25  5342     6     0    70     0     0     5     0]\n",
      " [    0    97    16  1220     0    12     4     0     9     0]\n",
      " [    0     9     1     0    34     2     1     0     0    15]\n",
      " [   24   103   168    12    13  1234    21    53   418    20]\n",
      " [    0  1101     1     0     0    17  4022     0     0    15]\n",
      " [    5     4     0     0     0     7     1    71     0     8]\n",
      " [    1    12   138    36     0    31     2     0 21201     0]\n",
      " [    0    76     0     0     0     7   106     1     0  6137]]\n",
      "0.9469359308902899\n",
      "0.9453554513969803\n",
      "0.9462641535164874\n",
      "0.9469359308902899\n",
      "0.8524135714220378\n",
      "0.8659768766127222\n",
      "0.8470406761093322\n",
      "0.8470406761093322\n"
     ]
    }
   ],
   "source": [
    "clf = clf\n",
    "x = X_val\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1516\n",
      "           1       0.93      0.97      0.95     18249\n",
      "           2       0.92      0.98      0.95      5448\n",
      "           3       0.88      0.90      0.89      1358\n",
      "           4       0.72      0.55      0.62        62\n",
      "           5       0.74      0.60      0.66      2066\n",
      "           6       0.95      0.78      0.86      5156\n",
      "           7       0.57      0.74      0.64        96\n",
      "           8       0.98      0.99      0.98     21421\n",
      "           9       0.99      0.97      0.98      6327\n",
      "\n",
      "    accuracy                           0.95     61699\n",
      "   macro avg       0.87      0.85      0.85     61699\n",
      "weighted avg       0.95      0.95      0.95     61699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'sensitivity_score' from 'sklearn.metrics' (/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sensitivity_score, false_positive_rate_score, specificity_score, false_negative_rate_score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sensitivity_score(y_val, y_pred))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(false_positive_rate_score(y_val, y_pred))\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'sensitivity_score' from 'sklearn.metrics' (/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import sensitivity_score, false_positive_rate_score, specificity_score, false_negative_rate_score\n",
    "\n",
    "# print(sensitivity_score(y_val, y_pred))\n",
    "# print(false_positive_rate_score(y_val, y_pred))\n",
    "# print(specificity_score(y_val, y_pred))\n",
    "# print(false_negative_rate_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minmax, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876138610651885\n"
     ]
    }
   ],
   "source": [
    "## minmax, threshold\n",
    "clf = svm.LinearSVC(random_state=seed)\n",
    "clf.fit(X_train_mod, y_train)\n",
    "y_pred = clf.predict(X_test_mod)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     0     0     0     0     0     1     0     0     0]\n",
      " [    0 16834   139    72     0     9   610     0   583     2]\n",
      " [    0    68  5357    11     0    12     0     0     0     0]\n",
      " [    0   189     8   545     0     3   528     0    85     0]\n",
      " [    1     5     4     0     3     1     0     0     0    48]\n",
      " [   38   161   175    13     7   902     7     0   725    38]\n",
      " [    0   888     1     9     2     4  2829     0   480   943]\n",
      " [   33    15     2     0     0     0     0     0    41     5]\n",
      " [    0   153   288   109     0    33    14     0 20824     0]\n",
      " [    0   238     8     0     4     3   137     0    22  5915]]\n",
      "0.8869511661453184\n",
      "0.8782729136303037\n",
      "0.8803700457326579\n",
      "0.8869511661453184\n",
      "0.645849877213308\n",
      "0.7047474629468323\n",
      "0.6247097072845886\n",
      "0.6247097072845886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = clf\n",
    "x = X_val_mod\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      1516\n",
      "           1       0.91      0.92      0.91     18249\n",
      "           2       0.90      0.98      0.94      5448\n",
      "           3       0.72      0.40      0.51      1358\n",
      "           4       0.19      0.05      0.08        62\n",
      "           5       0.93      0.44      0.59      2066\n",
      "           6       0.69      0.55      0.61      5156\n",
      "           7       0.00      0.00      0.00        96\n",
      "           8       0.91      0.97      0.94     21421\n",
      "           9       0.85      0.93      0.89      6327\n",
      "\n",
      "    accuracy                           0.89     61699\n",
      "   macro avg       0.70      0.62      0.65     61699\n",
      "weighted avg       0.88      0.89      0.88     61699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minmax, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8878245648157153\n"
     ]
    }
   ],
   "source": [
    "## minmax, no threshold\n",
    "clf = svm.LinearSVC(random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1515     0     0     0     0     0     1     0     0     0]\n",
      " [    0 16833   139    78     0     9   605     0   583     2]\n",
      " [    0    68  5357    11     0    12     0     0     0     0]\n",
      " [    0   189     8   568     0     3   505     0    85     0]\n",
      " [    1     5     4     0     3     1     0     0     0    48]\n",
      " [   38   161   175    12     7   902     7     0   725    39]\n",
      " [    0   888     1     7     2     4  2827     0   483   944]\n",
      " [   33    15     2     0     0     0     0     0    41     5]\n",
      " [    0   153   288   110     0    33    13     0 20824     0]\n",
      " [    0   237     8     0     4     3   136     0    22  5917]]\n",
      "0.8873077359438565\n",
      "0.878722295626932\n",
      "0.88082867470923\n",
      "0.8873077359438565\n",
      "0.6475110522783976\n",
      "0.7056663132132548\n",
      "0.6263907154882808\n",
      "0.6263907154882808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = clf\n",
    "x = X_val\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(f1_score(y_val, y_pred, average='weighted'))\n",
    "print(precision_score(y_val, y_pred, average='weighted'))\n",
    "print(recall_score(y_val, y_pred, average='weighted'))\n",
    "print(f1_score(y_val, y_pred, average='macro'))\n",
    "print(precision_score(y_val, y_pred, average='macro'))\n",
    "print(recall_score(y_val, y_pred, average='macro'))\n",
    "print(balanced_accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      1516\n",
      "           1       0.91      0.92      0.91     18249\n",
      "           2       0.90      0.98      0.94      5448\n",
      "           3       0.72      0.42      0.53      1358\n",
      "           4       0.19      0.05      0.08        62\n",
      "           5       0.93      0.44      0.59      2066\n",
      "           6       0.69      0.55      0.61      5156\n",
      "           7       0.00      0.00      0.00        96\n",
      "           8       0.91      0.97      0.94     21421\n",
      "           9       0.85      0.94      0.89      6327\n",
      "\n",
      "    accuracy                           0.89     61699\n",
      "   macro avg       0.71      0.63      0.65     61699\n",
      "weighted avg       0.88      0.89      0.88     61699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/filippobrajucha/Developer/data-analytics/.env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
