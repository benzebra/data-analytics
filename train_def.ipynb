{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torcheval.metrics as tm\n",
    "\n",
    "## TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "## Sklearn\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "\n",
    "from sklearn import preprocessing, decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "## Saving, Loading and Plotting\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "\n",
    "clf = 'svm'         # 'rf', 'svm', 'knn', 'ffnn', 'tabtansf' or 'tabnet'\n",
    "pre = 'lda'         # 'pca', 'lda' or 'std'\n",
    "overfit = True      # True or False\n",
    "\n",
    "ml = True           # DON'T CHANGE (True for Machine Learning, False for Deep Learning)\n",
    "\n",
    "if clf == 'ffnn' or clf == 'tabnet' or clf == 'tabtransf':\n",
    "    overfit = True\n",
    "    ml = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "        torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "        torch.backends.cuda.enable_flash_sdp(False)\n",
    "        torch.backends.cuda.enable_math_sdp(True)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    def fix_random(seed: int) -> None:\n",
    "        \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "        Args:\n",
    "            seed: the seed to use. \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    class MyDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            \n",
    "            self.X = torch.FloatTensor(X)\n",
    "            self.y = torch.LongTensor(y)\n",
    "            \n",
    "            self.num_features = X.shape[1]\n",
    "            self.num_classes = len(np.unique(y))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.X.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444240, 44) (444240,)\n",
      "(111061, 44) (111061,)\n",
      "(61701, 44) (61701,)\n"
     ]
    }
   ],
   "source": [
    "if overfit:\n",
    "    indeces = np.arange(X.shape[0])\n",
    "    train_idx, test_idx = train_test_split(indeces, test_size=0.1, stratify=y, random_state=SEED)\n",
    "    X_test = X[test_idx,:]\n",
    "    y_test = y[test_idx]\n",
    "    X = X[train_idx,:]\n",
    "    y = y[train_idx]\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "if overfit:\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "if pre == 'pca' or pre == 'lda':\n",
    "    if pre == 'pca':\n",
    "        pre = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "        pre.fit(X_train)\n",
    "    else:\n",
    "        pre = LinearDiscriminantAnalysis()\n",
    "        pre.fit(X_train, y_train)\n",
    "\n",
    "    X = pre.transform(X)\n",
    "\n",
    "    X_train = pre.transform(X_train)\n",
    "    X_val = pre.transform(X_val)\n",
    "\n",
    "    if overfit:\n",
    "        X_test = pre.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    train_dataset = MyDataset(X_train, y_train)\n",
    "    val_dataset = MyDataset(X_val, y_val)\n",
    "    test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'rf':\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [50, 100, 200],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    param_grid = {\n",
    "        'n_estimators': [50],\n",
    "        'criterion': ['gini']\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'svm':\n",
    "    # param_grid = {\n",
    "    #     'C': [0.1, 1, 10, 100, 1000], \n",
    "    #     'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    #     'gamma': ['scale', 'auto']  \n",
    "    # }\n",
    "    param_grid = {\n",
    "        'C': [1000], \n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['auto']  \n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'knn':\n",
    "    # param_grid = {\n",
    "    #     'n_neighbors': [10, 20, 50, 100, 500, 775, 900, 1000],\n",
    "    #     'p': [1, 2]\n",
    "    # }\n",
    "    param_grid = {\n",
    "        'n_neighbors': [2],\n",
    "        'p': [1]\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'ffnn':\n",
    "    # Architecture\n",
    "    class FeedForwardPlus(nn.Module):\n",
    "        def __init__(self, input_size, num_classes, hidden_size, depth=1, batch_norm=False, drop=0):\n",
    "            super(FeedForwardPlus, self).__init__()\n",
    "            \n",
    "            model = []\n",
    "            model += [nn.Linear(input_size, hidden_size)]\n",
    "            if batch_norm:\n",
    "                model += [nn.BatchNorm1d(hidden_size)]\n",
    "            model += [nn.ReLU()]\n",
    "\n",
    "            block = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_batch_norm = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_dropout = [\n",
    "                nn.Dropout(drop),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            for i in range(depth):\n",
    "                if not batch_norm and drop == 0:\n",
    "                    model += block\n",
    "                elif batch_norm and drop == 0:\n",
    "                    model += block_batch_norm\n",
    "                elif drop > 0 and not batch_norm:\n",
    "                    model += block_dropout\n",
    "            \n",
    "            self.model = nn.Sequential(*model)\n",
    "            \n",
    "            self.output = nn.Linear(hidden_size, num_classes)\n",
    "            \n",
    "\n",
    "        def forward(self, x):\n",
    "            h = self.model(x)\n",
    "            out = self.output(h)\n",
    "            return out\n",
    "\n",
    "\n",
    "    # Train function (f1 score with torcheval)\n",
    "    def train_model(model, criterion, optimizer, epoch, scheduler, train_loader, val_loader, device, writer, log_name=\"model\"):\n",
    "        n_iter = 0\n",
    "        best_valid_loss = float('inf')\n",
    "        for epoch in range(epoch):\n",
    "            model.train()\n",
    "            \n",
    "            for data, targets in train_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = model(data)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = criterion(y_pred, targets)\n",
    "            \n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                n_iter += 1\n",
    "            \n",
    "            labels, _, y_pred = test_model(model, val_loader, device)\n",
    "            loss_val = criterion(y_pred, labels)\n",
    "            \n",
    "            # Log the f1 score\n",
    "            f1 = tm.MulticlassF1Score(num_classes=labels.max().item() + 1)\n",
    "            f1.update(y_pred, labels)\n",
    "            writer.add_scalar(log_name, f1.compute().item(), epoch)\n",
    "            \n",
    "            # Save the best model (based on the validation loss)    \n",
    "            if loss_val.item() < best_valid_loss:\n",
    "                best_valid_loss = loss_val.item()\n",
    "                if not os.path.exists('models'):\n",
    "                    os.makedirs('models')\n",
    "                torch.save(model.state_dict(), 'models/'+log_name)\n",
    "            \n",
    "            (log_name, scheduler.get_last_lr()[0], epoch)\n",
    "            \n",
    "            scheduler.step()\n",
    "                \n",
    "        return model, best_valid_loss\n",
    "\n",
    "\n",
    "    # Evaluate the performance on validation and test sets\n",
    "    def test_model(model, data_loader, device):\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        \n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            y_pred += model(data)\n",
    "            y_test += targets\n",
    "        \n",
    "        y_test = torch.stack(y_test).squeeze()\n",
    "        y_pred = torch.stack(y_pred).squeeze()\n",
    "        y_pred_c = y_pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "        \n",
    "        return y_test, y_pred_c, y_pred\n",
    "\n",
    "\n",
    "    # Train settings \n",
    "    batch_sizes = [256, 512]\n",
    "    hidden_sizes = [16, 32, 64] # 64\n",
    "    batch_norm_list = [False, True]\n",
    "    drop = 0\n",
    "    depths = [2, 4, 8, 16]\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.01\n",
    "    gammas = [1, 0.5]\n",
    "    step_size = num_epochs / 4\n",
    "\n",
    "    hyperparameters = itertools.product(batch_sizes, hidden_sizes, depths, gammas, batch_norm_list)\n",
    "\n",
    "    lowest_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabTransf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'tabtransf':\n",
    "    # Architecture\n",
    "    class TabTransformer(torch.nn.Module):\n",
    "        def __init__(self, num_features, num_classes, dim_embedding=8, num_heads=2, num_layers=2):\n",
    "            super(TabTransformer, self).__init__()\n",
    "            self.embedding = torch.nn.Linear(num_features, dim_embedding)\n",
    "            encoder_layer = torch.nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, batch_first=True)\n",
    "            self.transformer = torch.nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "            self.classifier = torch.nn.Linear(dim_embedding, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.embedding(x)\n",
    "            x = x.unsqueeze(1)          # Adding a sequence length dimension\n",
    "            x = self.transformer(x)\n",
    "            x = torch.mean(x, dim=1)    # Pooling\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "        \n",
    "\n",
    "    # Train function (with early stopping)\n",
    "    def train_model(model, criterion, optimizer, epochs, data_loader, val_loader, device, scheduler, patience):\n",
    "        n_iter = 0\n",
    "        best_model = None\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_since_last_improvement = 0\n",
    "        loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "\n",
    "            start_epoch = time.time()\n",
    "\n",
    "            loss_train = 0\n",
    "            for data, targets in data_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                n_iter += 1\n",
    "                loss_train += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            loss_train /= len(data_loader)\n",
    "            # Compute Val Loss and add to history arrays\n",
    "            val_loss,_,_ = test_model(model, criterion, val_loader)\n",
    "            loss_history.append(loss_train)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                epochs_since_last_improvement = 0\n",
    "            elif epochs_since_last_improvement >= patience:\n",
    "                break\n",
    "            else:\n",
    "                epochs_since_last_improvement += 1\n",
    "\n",
    "            print('Epoch [{}/{}] - {:.2f} seconds - train_loss: {:.6f} - val_loss: {:.6f} - patience: {}'.format(\n",
    "                epoch+1,\n",
    "                epochs, \n",
    "                time.time() - start_epoch,\n",
    "                loss_train, \n",
    "                val_loss, \n",
    "                epochs_since_last_improvement), \n",
    "                end='\\r')\n",
    "\n",
    "        print('\\nTraining ended after {:.2f} seconds - Best val_loss: {:.6f}'.format(\n",
    "            time.time() - start, \n",
    "            best_val_loss))\n",
    "\n",
    "        return best_model, loss_history, val_loss_history\n",
    "\n",
    "\n",
    "    # Evaluate the performance on validation and test sets\n",
    "    def test_model(model, criterion, loader):\n",
    "        model.eval()\n",
    "        y_pred = torch.tensor([],requires_grad=True).to(device)\n",
    "        y_true = torch.tensor([],requires_grad=True).to(device)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for data, targets in loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, targets.long())\n",
    "            total_loss += loss.item()\n",
    "            y_pred = torch.cat((y_pred, preds.squeeze()))\n",
    "            y_true = torch.cat((y_true, targets.detach()))\n",
    "\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        return avg_loss, y_pred.squeeze(), y_true.squeeze()\n",
    "\n",
    "\n",
    "    # Train settings \n",
    "    nums_epochs = [10,20]\n",
    "    batch_sizes = [256,512]\n",
    "    patience = [10,20]\n",
    "    dim_embedding = [16,32]\n",
    "    num_heads = [8,16]\n",
    "    num_layers = [16,32]\n",
    "    learning_rate = [0.001]\n",
    "\n",
    "    hyperparameters = list(itertools.product(nums_epochs, batch_sizes, patience, dim_embedding, num_heads, num_layers, learning_rate))\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device))\n",
    "    current_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'tabnet':    \n",
    "    class TabNet(torch.nn.Module):\n",
    "        '''\n",
    "        Wrapper class for TabNetClassifier\n",
    "        '''\n",
    "        def __init__(self, n_d,\n",
    "                    n_a,\n",
    "                    n_steps,\n",
    "                    gamma,\n",
    "                    optimizer_fn,\n",
    "                    n_independent,\n",
    "                    n_shared,\n",
    "                    epsilon,\n",
    "                    seed,\n",
    "                    lambda_sparse,\n",
    "                    clip_value,\n",
    "                    momentum,\n",
    "                    optimizer_params,\n",
    "                    scheduler_params,\n",
    "                    mask_type,\n",
    "                    scheduler_fn,\n",
    "                    device_name,\n",
    "                    output_dim,\n",
    "                    batch_size,\n",
    "                    num_epochs,\n",
    "                    unsupervised_model,\n",
    "                    verbose=0):\n",
    "            super(TabNet, self).__init__()\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "            self.num_epochs = num_epochs\n",
    "            self.unsupervised_model = unsupervised_model\n",
    "            self.network = TabNetClassifier(n_d=n_d,\n",
    "                                            n_a=n_a,\n",
    "                                            n_steps=n_steps,\n",
    "                                            gamma=gamma,\n",
    "                                            optimizer_fn=optimizer_fn,\n",
    "                                            n_independent=n_independent,\n",
    "                                            n_shared=n_shared,\n",
    "                                            epsilon=epsilon,\n",
    "                                            seed=seed,\n",
    "                                            lambda_sparse=lambda_sparse,\n",
    "                                            clip_value=clip_value,\n",
    "                                            momentum=momentum,\n",
    "                                            optimizer_params=optimizer_params,\n",
    "                                            scheduler_params=scheduler_params,\n",
    "                                            mask_type=mask_type,\n",
    "                                            scheduler_fn=scheduler_fn,\n",
    "                                            device_name=device_name,\n",
    "                                            output_dim=output_dim,\n",
    "                                            verbose=verbose)\n",
    "        \n",
    "        def fit_model(self, X_train, y_train, X_val, y_val, criterion):\n",
    "            self.network.fit(X_train=X_train, \n",
    "                            y_train=y_train, \n",
    "                            eval_set=[(X_train,y_train),(X_val, y_val)], \n",
    "                            eval_metric=['balanced_accuracy'], \n",
    "                            patience=10, \n",
    "                            batch_size=self.batch_size, \n",
    "                            virtual_batch_size=128, \n",
    "                            num_workers=0, \n",
    "                            drop_last=True, \n",
    "                            max_epochs=self.num_epochs, \n",
    "                            loss_fn=criterion, \n",
    "                            from_unsupervised=self.unsupervised_model)\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.network.predict(X)\n",
    "        \n",
    "        def explain(self, X):\n",
    "            return self.network.explain(X)\n",
    "        \n",
    "        def feature_importances(self):\n",
    "            return self.network.feature_importances_\n",
    "\n",
    "    def get_unsupervised_model(n_d_a,n_step,n_independent,n_shared,gamma,lr):\n",
    "        tabnet_params = dict(n_d=n_d_a, \n",
    "                            n_a=n_d_a,\n",
    "                            n_steps=n_step,\n",
    "                            gamma=gamma,\n",
    "                            n_independent=n_independent,\n",
    "                            n_shared=n_shared,\n",
    "                            lambda_sparse=1e-3,\n",
    "                            optimizer_fn=torch.optim.AdamW, \n",
    "                            optimizer_params=dict(lr=lr),\n",
    "                            mask_type=\"sparsemax\",\n",
    "                            verbose=0\n",
    "                            )\n",
    "        unsupervised_model = TabNetPretrainer(**tabnet_params)\n",
    "        return unsupervised_model\n",
    "    \n",
    "\n",
    "    # Train settings\n",
    "    nums_epochs = [10]\n",
    "    batch_sizes = [512]\n",
    "    patience = [10,20]\n",
    "    n_d_a = [16]\n",
    "    n_shared = [8,16]\n",
    "    n_indipendents = [1] \n",
    "    n_steps = [8,9]\n",
    "    gamma = [1.0]\n",
    "    epsilon = [1e-15]\n",
    "    learning_rate = [0.01]\n",
    "    pretraining_ratio = [0.5]\n",
    "    momentum = [0.99]\n",
    "\n",
    "    hyperparameters = list(itertools.product(nums_epochs, batch_sizes, patience, n_d_a, n_indipendents, n_shared, n_steps, gamma, epsilon, learning_rate, pretraining_ratio, momentum))\n",
    "    \n",
    "    current_iter = 0\n",
    "    best_acc = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1; 1/1] START C=1000, gamma=auto, kernel=rbf..............................\n",
      "[CV 1/1; 1/1] END C=1000, gamma=auto, kernel=rbf; balanced_accuracy: (test=0.993) f1_weighted: (test=0.999) total time=  52.8s\n",
      "---------------------------------\n",
      "Best hyper:  SVC(C=1000, gamma='auto')\n",
      "Best score:  0.9931415922851924\n"
     ]
    }
   ],
   "source": [
    "if ml == True:\n",
    "    grid.fit(X, y)\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Best hyper: \", grid.best_estimator_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    best_clf = grid.best_estimator_\n",
    "else:\n",
    "    if clf == 'ffnn':\n",
    "        for batch_size, hidden_size, depth, gamma, batch_norm in hyperparameters:\n",
    "            fix_random(SEED)\n",
    "            \n",
    "            start = time.time()\n",
    "            log_name = \"B\"+str(batch_size)+\"-dim\"+str(hidden_size)+\"-dp\"+str(depth)+\"-ep\"+str(num_epochs)+\"-lr\"+str(learning_rate)+\"-steplr\"+str(step_size)+\"-gamma\"+str(gamma)+\"-BN\"+str(batch_norm)+\"-drop\"+str(drop)\n",
    "            print(log_name, end=\", \")\n",
    "            \n",
    "            writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "            # Create Dataloaders\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            # Define Architecture\n",
    "            model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "            model.to(device)\n",
    "                    \n",
    "            # Define Loss and Optimizer\n",
    "            criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(list(class_weights.values())).to(device))\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "            # Train the model\n",
    "            model, best_valid_loss = train_model(model, criterion, optimizer, num_epochs, scheduler, train_loader, val_loader, device, writer, log_name)\n",
    "\n",
    "            writer.add_hparams({'hparam/bsize': batch_size, 'hparam/hidden size': hidden_size, 'hparam/depth':depth+2, 'hparam/scheduler': gamma,'hparam/batch norm': batch_norm}, {'best loss': best_valid_loss})\n",
    "            writer.flush()\n",
    "\n",
    "            if best_valid_loss < lowest_loss:\n",
    "                best_model = model\n",
    "                lowest_loss = best_valid_loss\n",
    "                best_model_params = (batch_size, hidden_size, depth, gamma, batch_norm, log_name)\n",
    "\n",
    "            # Log the elapsed time\n",
    "            print(\"-- elpased time:\", time.time() - start)\n",
    "        writer.close()\n",
    "\n",
    "        # # Save the best model and its hyperparameters\n",
    "        # torch.save(best_model.state_dict(), 'models/best_model')\n",
    "        # with open('best_model_params.pkl', 'wb') as f:\n",
    "        #     pickle.dump(best_model_params, f)\n",
    "\n",
    "        # # Load the best model\n",
    "        # if best_model_params:\n",
    "        #     _, _, _, _, _, best_log_name = best_model_params\n",
    "        #     model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "    elif clf == 'tabtransf':\n",
    "        for epochs, batch_size, patience_, dim_embedding_, num_heads_, num_layers_, lr in hyperparameters:\n",
    "\n",
    "            print(f'Iteration {current_iter+1}/{len(hyperparameters)}')\n",
    "            print(f'Hyperparameters: epochs={epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  dim_embedding={dim_embedding_}, \n",
    "                  num_heads={num_heads_}, \n",
    "                  num_layers={num_layers_}, \n",
    "                  lr={lr}')\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=y_val.shape[0], shuffle=False)\n",
    "\n",
    "            model = TabTransformer(train_dataset.num_feature, train_dataset.num_classes).to(torch.device('cuda'))\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "            model, loss_history, val_loss_history = train_model(model, criterion, optimizer, epochs, train_loader, val_loader, device, scheduler, patience_)\n",
    "            \n",
    "            val_loss, y_pred, y_true = test_model(model, criterion, val_loader)\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_params = (epochs, batch_size, patience_, dim_embedding_, num_heads_, num_layers_, lr)\n",
    "\n",
    "            print(f'Hyperparameters: epochs={epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  dim_embedding={dim_embedding_}, \n",
    "                  num_heads={num_heads_}, \n",
    "                  num_layers={num_layers_}, \n",
    "                  lr={lr}')\n",
    "            print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "            current_iter += 1\n",
    "    \n",
    "    elif clf == 'tabnet':\n",
    "        for num_epochs, batch_size, patience_, n_d, n_i, n_s, n_steps_, gamma_, epsilon_, lr, pretraining_ratio_, moment in hyperparameters:\n",
    "    \n",
    "            print(f'Iteration {current_iter+1}/{len(hyperparameters)}')\n",
    "            print(f'Hyperparameters: epochs={num_epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  n_d={n_d}, \n",
    "                  n_indipendent={n_i}, \n",
    "                  n_shared={n_s}, \n",
    "                  n_steps={n_steps_}, \n",
    "                  gamma={gamma_}, \n",
    "                  epsilon={epsilon_}, \n",
    "                  lr={lr}, \n",
    "                  pretraining_ratio={pretraining_ratio_}, \n",
    "                  momentum={moment}')\n",
    "\n",
    "            unsupervised_model = get_unsupervised_model(n_d, n_steps_, n_i, n_s, gamma_, lr)\n",
    "                \n",
    "            unsupervised_model.fit(\n",
    "                X_train=X_train,\n",
    "                eval_set=[X_val],\n",
    "                max_epochs=num_epochs,\n",
    "                patience=patience_,\n",
    "                batch_size=batch_size,\n",
    "                virtual_batch_size=128,\n",
    "                num_workers=0,\n",
    "                drop_last=False,\n",
    "                pretraining_ratio=pretraining_ratio_,\n",
    "            )\n",
    "\n",
    "            model = TabNet(n_d=n_d,\n",
    "                        n_a=n_d,\n",
    "                        n_steps=n_steps_,\n",
    "                        gamma=gamma_,\n",
    "                        optimizer_fn=torch.optim.AdamW,\n",
    "                        n_independent=n_i,\n",
    "                        n_shared=n_s,\n",
    "                        epsilon=epsilon_,\n",
    "                        seed=SEED,\n",
    "                        lambda_sparse=1e-4,\n",
    "                        clip_value=1,\n",
    "                        momentum=moment,\n",
    "                        optimizer_params=dict(lr=lr),\n",
    "                        scheduler_params=dict(step_size=10, gamma=0.9),\n",
    "                        mask_type='sparsemax',\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                        device_name=device,\n",
    "                        output_dim=len(np.unique(y_train)),\n",
    "                        batch_size=batch_size,\n",
    "                        num_epochs=num_epochs,\n",
    "                        unsupervised_model=None,\n",
    "                        verbose=0)\n",
    "            \n",
    "            model.fit_model(X_train, y_train, X_val, y_val, criterion)    \n",
    "            y_pred = model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_params = (num_epochs, batch_size, patience_, n_d, n_i, n_s, n_steps_, gamma_, epsilon_, lr, pretraining_ratio_, moment)\n",
    "            \n",
    "            current_iter += 1\n",
    "\n",
    "    # Save the best model and its hyperparameters\n",
    "    torch.save(best_model.state_dict(), 'models/best_model')\n",
    "    with open('best_model_params.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model_params, f)\n",
    "\n",
    "    # Load the best model\n",
    "    if best_model_params:\n",
    "        if clf == 'ffnn':\n",
    "            batch_size, hidden_size, depth, gamma, batch_norm, best_log_name = best_model_params\n",
    "            model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "        elif clf == 'tabtransf':\n",
    "            epochs, batch_size, patience, dim_embedding, num_heads, num_layers, lr = best_model_params\n",
    "            model = TabTransformer(train_dataset.num_features, train_dataset.num_classes, dim_embedding=dim_embedding, num_heads=num_heads, num_layers=num_layers, lr=lr)\n",
    "        elif clf == 'tabnet':\n",
    "            num_epochs, batch_size, patience, n_d, n_i, n_s, n_steps, gamma, epsilon, lr, pretraining_ratio, moment = best_model_params\n",
    "            model = TabNet(n_d=n_d,\n",
    "                        n_a=n_d,\n",
    "                        n_steps=n_steps,\n",
    "                        gamma=gamma,\n",
    "                        optimizer_fn=torch.optim.AdamW,\n",
    "                        n_independent=n_i,\n",
    "                        n_shared=n_s,\n",
    "                        epsilon=epsilon,\n",
    "                        seed=SEED,\n",
    "                        lambda_sparse=1e-4,\n",
    "                        clip_value=1,\n",
    "                        momentum=moment,\n",
    "                        optimizer_params=dict(lr=lr),\n",
    "                        scheduler_params=dict(step_size=10, gamma=0.9),\n",
    "                        mask_type='sparsemax',\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                        device_name=device,\n",
    "                        output_dim=len(np.unique(y_train)),\n",
    "                        batch_size=batch_size,\n",
    "                        num_epochs=num_epochs,\n",
    "                        unsupervised_model=None,\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1516\n",
      "           1       1.00      1.00      1.00     18249\n",
      "           2       1.00      1.00      1.00      5448\n",
      "           3       1.00      1.00      1.00      1358\n",
      "           4       0.97      0.98      0.98        62\n",
      "           5       1.00      1.00      1.00      2068\n",
      "           6       1.00      1.00      1.00      5156\n",
      "           7       0.99      0.98      0.98        96\n",
      "           8       1.00      1.00      1.00     21421\n",
      "           9       1.00      1.00      1.00      6327\n",
      "\n",
      "    accuracy                           1.00     61701\n",
      "   macro avg       0.99      1.00      1.00     61701\n",
      "weighted avg       1.00      1.00      1.00     61701\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ml:\n",
    "    classes = best_clf.classes_\n",
    "    \n",
    "    if overfit:\n",
    "        y_pred = best_clf.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        report = print(classification_report(y_test, y_pred))    \n",
    "    else:\n",
    "        y_pred = best_clf.predict(X_val)\n",
    "        cm = confusion_matrix(y_val, y_pred, labels=classes)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "        disp.plot()\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "else:\n",
    "    if clf == 'ffnn':\n",
    "        # Evaluate the best model on the test set\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_sizes[0])\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        y_test, y_pred_c, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "    elif clf == 'tabtransf':\n",
    "        test_loader = DataLoader(test_dataset, batch_size=y_test.shape[0], shuffle=False)\n",
    "\n",
    "        _, y_pred, y_true = test_model(model, criterion, test_loader)\n",
    "        y_pred_c = y_pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "\n",
    "    elif clf == 'tabnet':\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=y_test.max().item() + 1)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_test.max().item() + 1)\n",
    "        disp.plot()\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    if clf != 'tabnet':\n",
    "        # Print Accuracy, Precision, F1 Score and Confusion Matrix\n",
    "        print(f\"Accuracy: {:.4f} --\\t Precision: {:.4f} --\\t F1: {:.4f} --\\t Balanced Accuracy: {:.4f}\".format( \n",
    "            tm.MulticlassAccuracy().update(y_pred_c, y_test).compute().item(), \n",
    "            tm.MulticlassPrecision(num_classes=y_test.max().item() + 1).update(y_pred, y_test).compute().item(),\n",
    "            tm.MulticlassF1Score(num_classes=y_test.max().item() + 1, ).update(y_pred, y_test),\n",
    "            balanced_accuracy_score(y_test.cpu().numpy(), y_pred_c.cpu().numpy())))\n",
    "\n",
    "        print(classification_report(y_test.cpu().numpy(), y_pred_c.cpu().numpy()))\n",
    "        conf_matrix = tm.MulticlassConfusionMatrix(num_classes=y_test.max().item() + 1)\n",
    "        conf_matrix.update(y_pred_c, y_test)\n",
    "        ConfusionMatrixDisplay(conf_matrix.compute().cpu().numpy()).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994975770246836\n",
      "0.9955736971973893\n",
      "0.9994976587240768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Classification Report}\n",
      "\\label{tab:classification_report}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Class & Precision & Recall & F1-Score & Support \\\\\n",
      "\\midrule\n",
      "0 & 1.00 & 1.00 & 1.00 & 1516.00 \\\\\n",
      "1 & 1.00 & 1.00 & 1.00 & 18249.00 \\\\\n",
      "2 & 1.00 & 1.00 & 1.00 & 5448.00 \\\\\n",
      "3 & 1.00 & 1.00 & 1.00 & 1358.00 \\\\\n",
      "4 & 0.97 & 0.98 & 0.98 & 62.00 \\\\\n",
      "5 & 1.00 & 1.00 & 1.00 & 2068.00 \\\\\n",
      "6 & 1.00 & 1.00 & 1.00 & 5156.00 \\\\\n",
      "7 & 0.99 & 0.98 & 0.98 & 96.00 \\\\\n",
      "8 & 1.00 & 1.00 & 1.00 & 21421.00 \\\\\n",
      "9 & 1.00 & 1.00 & 1.00 & 6327.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "# Parse the classification report into a pandas DataFrame\n",
    "lines = report.splitlines()\n",
    "\n",
    "# Collect rows for DataFrame\n",
    "rows = []\n",
    "for line in lines[2:-3]:  # Ignore the header and footer\n",
    "    row = line.split()\n",
    "    if len(row) < 2:\n",
    "        continue\n",
    "    # Combine the first column (e.g., class label) and the rest\n",
    "    label = row[0]\n",
    "    values = row[1:]\n",
    "    rows.append([label] + list(map(float, values)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = df.to_latex(index=False, float_format=\"%.2f\", caption=\"Classification Report\", label=\"tab:classification_report\")\n",
    "\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
