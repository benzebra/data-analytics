{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torcheval.metrics as tm\n",
    "\n",
    "## Sklearn\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "\n",
    "from sklearn import preprocessing, decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "## Saving, Loading and Plotting\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "\n",
    "clf = 'rf'          # 'rf', 'svm' or 'knn'\n",
    "pre = 'std'         # 'pca', 'lda' or 'std'\n",
    "overfit = True      # True or False\n",
    "\n",
    "ml = True           # DON'T CHANGE (True for Machine Learning, False for Deep Learning)\n",
    "\n",
    "if clf == 'ffnn' or clf == 'tabnet' or clf == 'tabtransf':\n",
    "    overfit = True\n",
    "    ml = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    def fix_random(seed: int) -> None:\n",
    "        \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "        Args:\n",
    "            seed: the seed to use. \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    class MyDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            \n",
    "            self.X = torch.FloatTensor(X)\n",
    "            self.y = torch.LongTensor(y)\n",
    "            \n",
    "            self.num_features = X.shape[1]\n",
    "            self.num_classes = len(np.unique(y))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.X.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overfit:\n",
    "    indeces = np.arange(X.shape[0])\n",
    "    train_idx, test_idx = train_test_split(indeces, test_size=0.1, stratify=y, random_state=SEED)\n",
    "    X_test = X[test_idx,:]\n",
    "    y_test = y[test_idx]\n",
    "    X = X[train_idx,:]\n",
    "    y = y[train_idx]\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "if pre == 'pca' or pre == 'lda':\n",
    "    if pre == 'pca':\n",
    "        pre = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "        pre.fit(X_train)\n",
    "    else:\n",
    "        pre = LinearDiscriminantAnalysis()\n",
    "        pre.fit(X_train, y_train)\n",
    "\n",
    "    X = pre.transform(X)\n",
    "\n",
    "    X_train = pre.transform(X_train)\n",
    "    X_val = pre.transform(X_val)\n",
    "\n",
    "    if overfit:\n",
    "        X_test = pre.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    train_dataset = MyDataset(X_train, y_train)\n",
    "    val_dataset = MyDataset(X_val, y_val)\n",
    "    test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'rf':\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 20, 35, 50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'svm':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100, 1000], \n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']  \n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'knn':\n",
    "    param_grid = {\n",
    "        'n_neighbors': [10, 20, 50, 100, 500, 775, 900, 1000],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    # Architecture\n",
    "    class FeedForwardPlus(nn.Module):\n",
    "        def __init__(self, input_size, num_classes, hidden_size, depth=1, batch_norm=False, drop=0):\n",
    "            super(FeedForwardPlus, self).__init__()\n",
    "            \n",
    "            model = []\n",
    "            model += [nn.Linear(input_size, hidden_size)]\n",
    "            if batch_norm:\n",
    "                model += [nn.BatchNorm1d(hidden_size)]\n",
    "            model += [nn.ReLU()]\n",
    "\n",
    "            block = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_batch_norm = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_dropout = [\n",
    "                nn.Dropout(drop),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            for i in range(depth):\n",
    "                if not batch_norm and drop == 0:\n",
    "                    model += block\n",
    "                elif batch_norm and drop == 0:\n",
    "                    model += block_batch_norm\n",
    "                elif drop > 0 and not batch_norm:\n",
    "                    model += block_dropout\n",
    "            \n",
    "            self.model = nn.Sequential(*model)\n",
    "            \n",
    "            self.output = nn.Linear(hidden_size, num_classes)\n",
    "            \n",
    "\n",
    "        def forward(self, x):\n",
    "            h = self.model(x)\n",
    "            out = self.output(h)\n",
    "            return out\n",
    "\n",
    "\n",
    "    # Train function (f1 score with torcheval)\n",
    "    def train_model(model, criterion, optimizer, epoch, scheduler, train_loader, val_loader, device, writer, log_name=\"model\"):\n",
    "        n_iter = 0\n",
    "        best_valid_loss = float('inf')\n",
    "        for epoch in range(epoch):\n",
    "            model.train()\n",
    "            \n",
    "            for data, targets in train_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = model(data)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = criterion(y_pred, targets)\n",
    "            \n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                n_iter += 1\n",
    "            \n",
    "            labels, _, y_pred = test_model(model, val_loader, device)\n",
    "            loss_val = criterion(y_pred, labels)\n",
    "            \n",
    "            # Log the f1 score\n",
    "            f1 = tm.MulticlassF1Score(num_classes=labels.max().item() + 1)\n",
    "            f1.update(y_pred, labels)\n",
    "            writer.add_scalar(log_name, f1.compute().item(), epoch)\n",
    "            \n",
    "            # Save the best model (based on the validation loss)    \n",
    "            if loss_val.item() < best_valid_loss:\n",
    "                best_valid_loss = loss_val.item()\n",
    "                if not os.path.exists('models'):\n",
    "                    os.makedirs('models')\n",
    "                torch.save(model.state_dict(), 'models/'+log_name)\n",
    "            \n",
    "            (log_name, scheduler.get_last_lr()[0], epoch)\n",
    "            \n",
    "            scheduler.step()\n",
    "                \n",
    "        return model, best_valid_loss\n",
    "\n",
    "\n",
    "    # Evaluate the performance on validation and test sets\n",
    "    def test_model(model, data_loader, device):\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        \n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            y_pred += model(data)\n",
    "            y_test += targets\n",
    "        \n",
    "        y_test = torch.stack(y_test).squeeze()\n",
    "        y_pred = torch.stack(y_pred).squeeze()\n",
    "        y_pred_c = y_pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "        \n",
    "        return y_test, y_pred_c, y_pred\n",
    "\n",
    "\n",
    "    # Train settings \n",
    "    batch_sizes = [256, 512]\n",
    "    hidden_sizes = [16, 32, 64] # 64\n",
    "    batch_norm_list = [False, True]\n",
    "    drop = 0\n",
    "    depths = [2, 4, 8, 16]\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.01\n",
    "    gammas = [1, 0.5]\n",
    "    step_size = num_epochs / 4\n",
    "\n",
    "    hyperparameters = itertools.product(batch_sizes, hidden_sizes, depths, gammas, batch_norm_list)\n",
    "\n",
    "    lowest_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 12 candidates, totalling 12 fits\n",
      "[CV 1/1; 5/12] START criterion=gini, n_estimators=100...........................\n",
      "[CV 1/1; 8/12] START criterion=entropy, n_estimators=20.........................\n",
      "[CV 1/1; 2/12] START criterion=gini, n_estimators=20............................\n",
      "[CV 1/1; 7/12] START criterion=entropy, n_estimators=10.........................\n",
      "[CV 1/1; 1/12] START criterion=gini, n_estimators=10............................\n",
      "[CV 1/1; 4/12] START criterion=gini, n_estimators=50............................\n",
      "[CV 1/1; 6/12] START criterion=gini, n_estimators=200...........................\n",
      "[CV 1/1; 3/12] START criterion=gini, n_estimators=35............................\n",
      "[CV 1/1; 7/12] END criterion=entropy, n_estimators=10; balanced_accuracy: (test=0.999) f1_weighted: (test=1.000) total time=  20.7s\n",
      "[CV 1/1; 1/12] END criterion=gini, n_estimators=10; balanced_accuracy: (test=0.999) f1_weighted: (test=1.000) total time=  21.2s\n",
      "[CV 1/1; 9/12] START criterion=entropy, n_estimators=35.........................\n",
      "[CV 1/1; 10/12] START criterion=entropy, n_estimators=50........................\n",
      "[CV 1/1; 2/12] END criterion=gini, n_estimators=20; balanced_accuracy: (test=0.997) f1_weighted: (test=1.000) total time=  36.9s\n",
      "[CV 1/1; 11/12] START criterion=entropy, n_estimators=100.......................\n",
      "[CV 1/1; 8/12] END criterion=entropy, n_estimators=20; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time=  37.5s\n",
      "[CV 1/1; 12/12] START criterion=entropy, n_estimators=200.......................\n",
      "[CV 1/1; 3/12] END criterion=gini, n_estimators=35; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time=  59.6s\n",
      "[CV 1/1; 9/12] END criterion=entropy, n_estimators=35; balanced_accuracy: (test=0.998) f1_weighted: (test=1.000) total time=  55.8s\n"
     ]
    }
   ],
   "source": [
    "if ml == True:\n",
    "    grid.fit(X, y)\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Best hyper: \", grid.best_estimator_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    best_clf = grid.best_estimator_\n",
    "else: \n",
    "    for batch_size, hidden_size, depth, gamma, batch_norm in hyperparameters:\n",
    "        fix_random(SEED)\n",
    "        \n",
    "        start = time.time()\n",
    "        log_name = \"B\"+str(batch_size)+\"-dim\"+str(hidden_size)+\"-dp\"+str(depth)+\"-ep\"+str(num_epochs)+\"-lr\"+str(learning_rate)+\"-steplr\"+str(step_size)+\"-gamma\"+str(gamma)+\"-BN\"+str(batch_norm)+\"-drop\"+str(drop)\n",
    "        print(log_name, end=\", \")\n",
    "        \n",
    "        writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "        # Create Dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Define Architecture\n",
    "        model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "        model.to(device)\n",
    "                \n",
    "        # Define Loss and Optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(list(class_weights.values())).to(device))\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "        # Train the model\n",
    "        model, best_valid_loss = train_model(model, criterion, optimizer, num_epochs, scheduler, train_loader, val_loader, device, writer, log_name)\n",
    "\n",
    "        writer.add_hparams({'hparam/bsize': batch_size, 'hparam/hidden size': hidden_size, 'hparam/depth':depth+2, 'hparam/scheduler': gamma,'hparam/batch norm': batch_norm}, {'best loss': best_valid_loss})\n",
    "        writer.flush()\n",
    "\n",
    "        if best_valid_loss < lowest_loss:\n",
    "            best_model = model\n",
    "            lowest_loss = best_valid_loss\n",
    "            best_model_params = (batch_size, hidden_size, depth, gamma, batch_norm, log_name)\n",
    "\n",
    "        # Log the elapsed time\n",
    "        print(\"-- elpased time:\", time.time() - start)\n",
    "    writer.close()\n",
    "\n",
    "    # Save the best model and its hyperparameters\n",
    "    torch.save(best_model.state_dict(), 'models/best_model')\n",
    "    with open('best_model_params.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model_params, f)\n",
    "\n",
    "    # Load the best model\n",
    "    if best_model_params:\n",
    "        _, _, _, _, _, best_log_name = best_model_params\n",
    "        model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ml:\n",
    "    if overfit:\n",
    "        cm = confusion_matrix(y_test, best_clf.predict(X_test), labels=best_clf.classes_)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_clf.classes_)\n",
    "        disp.plot()\n",
    "        print(classification_report(y_test, best_clf.predict(X_test)))\n",
    "    else:\n",
    "        cm = confusion_matrix(y_val, best_clf.predict(X_val), labels=best_clf.classes_)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_clf.classes_)\n",
    "        disp.plot()\n",
    "else:\n",
    "    # Evaluate the best model on the test set\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_sizes[0])\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    y_test, y_pred_c, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "    # Print Accuracy, Precision, F1 Score and Confusion Matrix\n",
    "    print(f\"Accuracy: {.4} --\\t Precision: {.4} --\\t F1: {.4} --\\t Balanced Accuracy: {.4}\", \n",
    "          tm.MulticlassAccuracy().update(y_pred_c, y_test).compute().item(), \n",
    "          tm.MulticlassPrecision(num_classes=y_test.max().item() + 1).update(y_pred, y_test).compute().item(),\n",
    "          tm.MulticlassF1Score(num_classes=y_test.max().item() + 1, ).update(y_pred, y_test),\n",
    "          balanced_accuracy_score(y_test.cpu().numpy(), y_pred_c.cpu().numpy()))\n",
    "\n",
    "    print(classification_report(y_test.cpu().numpy(), y_pred_c.cpu().numpy()))\n",
    "    conf_matrix = tm.MulticlassConfusionMatrix(num_classes=y_test.max().item() + 1)\n",
    "    conf_matrix.update(y_pred_c, y_test)\n",
    "    ConfusionMatrixDisplay(conf_matrix.compute().cpu().numpy()).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
