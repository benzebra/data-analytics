{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torcheval.metrics as tm\n",
    "\n",
    "## TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "## Sklearn\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "\n",
    "from sklearn import preprocessing, decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "## Saving, Loading and Plotting\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FILENAME = \"train_dataset.csv\"\n",
    "\n",
    "clf = 'knn'         # 'rf', 'svm', 'knn', 'ffnn', 'tabtansf' or 'tabnet'\n",
    "pre = 'std'         # 'pca', 'lda' or 'std'\n",
    "overfit = True      # True or False\n",
    "\n",
    "ml = True           # DON'T CHANGE (True for Machine Learning, False for Deep Learning)\n",
    "\n",
    "if clf == 'ffnn' or clf == 'tabnet' or clf == 'tabtransf':\n",
    "    overfit = True\n",
    "    ml = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "        torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "        torch.backends.cuda.enable_flash_sdp(False)\n",
    "        torch.backends.cuda.enable_math_sdp(True)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    def fix_random(seed: int) -> None:\n",
    "        \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "        Args:\n",
    "            seed: the seed to use. \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, sep=\",\", low_memory=False)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=[\"label\"])\n",
    "\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].replace(\"0.0.0.0\", np.nan).astype(float)\n",
    "mean_src_bytes = df[\"src_bytes\"].mean()\n",
    "df[\"src_bytes\"] = df[\"src_bytes\"].fillna(mean_src_bytes)\n",
    "\n",
    "df.astype({'src_bytes': 'int64', 'ts': 'datetime64[ms]', 'dns_AA': 'bool', 'dns_RD': 'bool', 'dns_RA': 'bool', 'dns_rejected': 'bool', 'ssl_resumed': 'bool', 'ssl_established': 'bool', 'weird_notice': 'bool'}).dtypes\n",
    "\n",
    "y = df[\"type\"]\n",
    "df = df.drop(columns=[\"type\"])\n",
    "\n",
    "oe = preprocessing.OrdinalEncoder()\n",
    "df_oe = oe.fit_transform(df.select_dtypes(include=['object']))\n",
    "df.loc[:, df.select_dtypes(include=['object']).columns] = df_oe\n",
    "X = df.to_numpy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    class MyDataset(Dataset):\n",
    "        def __init__(self, X, y):\n",
    "            \n",
    "            self.X = torch.FloatTensor(X)\n",
    "            self.y = torch.LongTensor(y)\n",
    "            \n",
    "            self.num_features = X.shape[1]\n",
    "            self.num_classes = len(np.unique(y))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.X.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444240, 44) (444240,)\n",
      "(111061, 44) (111061,)\n",
      "(61701, 44) (61701,)\n"
     ]
    }
   ],
   "source": [
    "if overfit:\n",
    "    indeces = np.arange(X.shape[0])\n",
    "    train_idx, test_idx = train_test_split(indeces, test_size=0.1, stratify=y, random_state=SEED)\n",
    "    X_test = X[test_idx,:]\n",
    "    y_test = y[test_idx]\n",
    "    X_tmp = X[train_idx,:]\n",
    "    y_tmp = y[train_idx]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    X = X_tmp\n",
    "    y = y_tmp\n",
    "\n",
    "indeces = np.arange(X.shape[0])\n",
    "train_idx, val_idx = train_test_split(indeces, test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "fold = np.zeros(X.shape[0])\n",
    "fold[train_idx] = -1\n",
    "fold[val_idx] = 0\n",
    "\n",
    "ps = PredefinedSplit(fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "X_train = X[train_idx,:]\n",
    "y_train = y[train_idx]\n",
    "X_val = X[val_idx,:]\n",
    "y_val = y[val_idx]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "if overfit:\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "if pre == 'pca' or pre == 'lda':\n",
    "    if pre == 'pca':\n",
    "        pre = decomposition.PCA(n_components='mle', svd_solver='full')\n",
    "        pre.fit(X_train)\n",
    "    else:\n",
    "        pre = LinearDiscriminantAnalysis()\n",
    "        pre.fit(X_train, y_train)\n",
    "\n",
    "    X = pre.transform(X)\n",
    "\n",
    "    X_train = pre.transform(X_train)\n",
    "    X_val = pre.transform(X_val)\n",
    "\n",
    "    if overfit:\n",
    "        X_test = pre.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ml:\n",
    "    train_dataset = MyDataset(X_train, y_train)\n",
    "    val_dataset = MyDataset(X_val, y_val)\n",
    "    test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'rf':\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [50, 100, 200],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    param_grid = {\n",
    "        'n_estimators': [50],\n",
    "        'criterion': ['gini']\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'svm':\n",
    "    # param_grid = {\n",
    "    #     'C': [0.1, 1, 10, 100, 1000], \n",
    "    #     'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    #     'gamma': ['scale', 'auto']  \n",
    "    # }\n",
    "    param_grid = {\n",
    "        'C': [1000], \n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['auto']  \n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'knn':\n",
    "    # param_grid = {\n",
    "    #     'n_neighbors': [10, 20, 50, 100, 500, 775, 900, 1000],\n",
    "    #     'p': [1, 2]\n",
    "    # }\n",
    "    param_grid = {\n",
    "        'n_neighbors': [2],\n",
    "        'p': [1]\n",
    "    }\n",
    "\n",
    "    scoring = ['balanced_accuracy', 'f1_weighted']\n",
    "\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ps, scoring=scoring, n_jobs=-1, verbose=10, refit='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'ffnn':\n",
    "    # Architecture\n",
    "    class FeedForwardPlus(nn.Module):\n",
    "        def __init__(self, input_size, num_classes, hidden_size, depth=1, batch_norm=False, drop=0):\n",
    "            super(FeedForwardPlus, self).__init__()\n",
    "            \n",
    "            model = []\n",
    "            model += [nn.Linear(input_size, hidden_size)]\n",
    "            if batch_norm:\n",
    "                model += [nn.BatchNorm1d(hidden_size)]\n",
    "            model += [nn.ReLU()]\n",
    "\n",
    "            block = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_batch_norm = [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            block_dropout = [\n",
    "                nn.Dropout(drop),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "\n",
    "            for i in range(depth):\n",
    "                if not batch_norm and drop == 0:\n",
    "                    model += block\n",
    "                elif batch_norm and drop == 0:\n",
    "                    model += block_batch_norm\n",
    "                elif drop > 0 and not batch_norm:\n",
    "                    model += block_dropout\n",
    "            \n",
    "            self.model = nn.Sequential(*model)\n",
    "            \n",
    "            self.output = nn.Linear(hidden_size, num_classes)\n",
    "            \n",
    "\n",
    "        def forward(self, x):\n",
    "            h = self.model(x)\n",
    "            out = self.output(h)\n",
    "            return out\n",
    "\n",
    "\n",
    "    # Train function (f1 score with torcheval)\n",
    "    def train_model(model, criterion, optimizer, epoch, scheduler, train_loader, val_loader, device, writer, log_name=\"model\"):\n",
    "        n_iter = 0\n",
    "        best_valid_loss = float('inf')\n",
    "        for epoch in range(epoch):\n",
    "            model.train()\n",
    "            \n",
    "            for data, targets in train_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = model(data)\n",
    "\n",
    "                # Compute Loss\n",
    "                loss = criterion(y_pred, targets)\n",
    "            \n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                n_iter += 1\n",
    "            \n",
    "            labels, _, y_pred = test_model(model, val_loader, device)\n",
    "            loss_val = criterion(y_pred, labels)\n",
    "            \n",
    "            # Log the f1 score\n",
    "            f1 = tm.MulticlassF1Score(num_classes=labels.max().item() + 1)\n",
    "            f1.update(y_pred, labels)\n",
    "            writer.add_scalar(log_name, f1.compute().item(), epoch)\n",
    "            \n",
    "            # Save the best model (based on the validation loss)    \n",
    "            if loss_val.item() < best_valid_loss:\n",
    "                best_valid_loss = loss_val.item()\n",
    "                if not os.path.exists('models'):\n",
    "                    os.makedirs('models')\n",
    "                torch.save(model.state_dict(), 'models/'+log_name)\n",
    "            \n",
    "            (log_name, scheduler.get_last_lr()[0], epoch)\n",
    "            \n",
    "            scheduler.step()\n",
    "                \n",
    "        return model, best_valid_loss\n",
    "\n",
    "\n",
    "    # Evaluate the performance on validation and test sets\n",
    "    def test_model(model, data_loader, device):\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_test = []\n",
    "        \n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            y_pred += model(data)\n",
    "            y_test += targets\n",
    "        \n",
    "        y_test = torch.stack(y_test).squeeze()\n",
    "        y_pred = torch.stack(y_pred).squeeze()\n",
    "        y_pred_c = y_pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "        \n",
    "        return y_test, y_pred_c, y_pred\n",
    "\n",
    "\n",
    "    # Train settings \n",
    "    batch_sizes = [256, 512]\n",
    "    hidden_sizes = [16, 32, 64] # 64\n",
    "    batch_norm_list = [False, True]\n",
    "    drop = 0\n",
    "    depths = [2, 4, 8, 16]\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.01\n",
    "    gammas = [1, 0.5]\n",
    "    step_size = num_epochs / 4\n",
    "\n",
    "    hyperparameters = itertools.product(batch_sizes, hidden_sizes, depths, gammas, batch_norm_list)\n",
    "\n",
    "    lowest_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabTransf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'tabtransf':\n",
    "    # Architecture\n",
    "    class TabTransformer(torch.nn.Module):\n",
    "        def __init__(self, num_features, num_classes, dim_embedding=8, num_heads=2, num_layers=2):\n",
    "            super(TabTransformer, self).__init__()\n",
    "            self.embedding = torch.nn.Linear(num_features, dim_embedding)\n",
    "            encoder_layer = torch.nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, batch_first=True)\n",
    "            self.transformer = torch.nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "            self.classifier = torch.nn.Linear(dim_embedding, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.embedding(x)\n",
    "            x = x.unsqueeze(1)          # Adding a sequence length dimension\n",
    "            x = self.transformer(x)\n",
    "            x = torch.mean(x, dim=1)    # Pooling\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "        \n",
    "\n",
    "    # Train function (with early stopping)\n",
    "    def train_model(model, criterion, optimizer, epochs, data_loader, val_loader, device, scheduler, patience):\n",
    "        n_iter = 0\n",
    "        best_model = None\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_since_last_improvement = 0\n",
    "        loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "\n",
    "            start_epoch = time.time()\n",
    "\n",
    "            loss_train = 0\n",
    "            for data, targets in data_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                n_iter += 1\n",
    "                loss_train += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "            loss_train /= len(data_loader)\n",
    "            # Compute Val Loss and add to history arrays\n",
    "            val_loss,_,_ = test_model(model, criterion, val_loader)\n",
    "            loss_history.append(loss_train)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                epochs_since_last_improvement = 0\n",
    "            elif epochs_since_last_improvement >= patience:\n",
    "                break\n",
    "            else:\n",
    "                epochs_since_last_improvement += 1\n",
    "\n",
    "            print('Epoch [{}/{}] - {:.2f} seconds - train_loss: {:.6f} - val_loss: {:.6f} - patience: {}'.format(\n",
    "                epoch+1,\n",
    "                epochs, \n",
    "                time.time() - start_epoch,\n",
    "                loss_train, \n",
    "                val_loss, \n",
    "                epochs_since_last_improvement), \n",
    "                end='\\r')\n",
    "\n",
    "        print('\\nTraining ended after {:.2f} seconds - Best val_loss: {:.6f}'.format(\n",
    "            time.time() - start, \n",
    "            best_val_loss))\n",
    "\n",
    "        return best_model, loss_history, val_loss_history\n",
    "\n",
    "\n",
    "    # Evaluate the performance on validation and test sets\n",
    "    def test_model(model, criterion, loader):\n",
    "        model.eval()\n",
    "        y_pred = torch.tensor([],requires_grad=True).to(device)\n",
    "        y_true = torch.tensor([],requires_grad=True).to(device)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for data, targets in loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            preds = model(data)\n",
    "            loss = criterion(preds, targets.long())\n",
    "            total_loss += loss.item()\n",
    "            y_pred = torch.cat((y_pred, preds.squeeze()))\n",
    "            y_true = torch.cat((y_true, targets.detach()))\n",
    "\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        return avg_loss, y_pred.squeeze(), y_true.squeeze()\n",
    "\n",
    "\n",
    "    # Train settings \n",
    "    nums_epochs = [10,20]\n",
    "    batch_sizes = [256,512]\n",
    "    patience = [10,20]\n",
    "    dim_embedding = [16,32]\n",
    "    num_heads = [8,16]\n",
    "    num_layers = [16,32]\n",
    "    learning_rate = [0.001]\n",
    "\n",
    "    hyperparameters = list(itertools.product(nums_epochs, batch_sizes, patience, dim_embedding, num_heads, num_layers, learning_rate))\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device))\n",
    "    current_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf == 'tabnet':    \n",
    "    class TabNet(torch.nn.Module):\n",
    "        '''\n",
    "        Wrapper class for TabNetClassifier\n",
    "        '''\n",
    "        def __init__(self, n_d,\n",
    "                    n_a,\n",
    "                    n_steps,\n",
    "                    gamma,\n",
    "                    optimizer_fn,\n",
    "                    n_independent,\n",
    "                    n_shared,\n",
    "                    epsilon,\n",
    "                    seed,\n",
    "                    lambda_sparse,\n",
    "                    clip_value,\n",
    "                    momentum,\n",
    "                    optimizer_params,\n",
    "                    scheduler_params,\n",
    "                    mask_type,\n",
    "                    scheduler_fn,\n",
    "                    device_name,\n",
    "                    output_dim,\n",
    "                    batch_size,\n",
    "                    num_epochs,\n",
    "                    unsupervised_model,\n",
    "                    verbose=0):\n",
    "            super(TabNet, self).__init__()\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "            self.num_epochs = num_epochs\n",
    "            self.unsupervised_model = unsupervised_model\n",
    "            self.network = TabNetClassifier(n_d=n_d,\n",
    "                                            n_a=n_a,\n",
    "                                            n_steps=n_steps,\n",
    "                                            gamma=gamma,\n",
    "                                            optimizer_fn=optimizer_fn,\n",
    "                                            n_independent=n_independent,\n",
    "                                            n_shared=n_shared,\n",
    "                                            epsilon=epsilon,\n",
    "                                            seed=seed,\n",
    "                                            lambda_sparse=lambda_sparse,\n",
    "                                            clip_value=clip_value,\n",
    "                                            momentum=momentum,\n",
    "                                            optimizer_params=optimizer_params,\n",
    "                                            scheduler_params=scheduler_params,\n",
    "                                            mask_type=mask_type,\n",
    "                                            scheduler_fn=scheduler_fn,\n",
    "                                            device_name=device_name,\n",
    "                                            output_dim=output_dim,\n",
    "                                            verbose=verbose)\n",
    "        \n",
    "        def fit_model(self, X_train, y_train, X_val, y_val, criterion):\n",
    "            self.network.fit(X_train=X_train, \n",
    "                            y_train=y_train, \n",
    "                            eval_set=[(X_train,y_train),(X_val, y_val)], \n",
    "                            eval_metric=['balanced_accuracy'], \n",
    "                            patience=10, \n",
    "                            batch_size=self.batch_size, \n",
    "                            virtual_batch_size=128, \n",
    "                            num_workers=0, \n",
    "                            drop_last=True, \n",
    "                            max_epochs=self.num_epochs, \n",
    "                            loss_fn=criterion, \n",
    "                            from_unsupervised=self.unsupervised_model)\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.network.predict(X)\n",
    "        \n",
    "        def explain(self, X):\n",
    "            return self.network.explain(X)\n",
    "        \n",
    "        def feature_importances(self):\n",
    "            return self.network.feature_importances_\n",
    "\n",
    "    def get_unsupervised_model(n_d_a,n_step,n_independent,n_shared,gamma,lr):\n",
    "        tabnet_params = dict(n_d=n_d_a, \n",
    "                            n_a=n_d_a,\n",
    "                            n_steps=n_step,\n",
    "                            gamma=gamma,\n",
    "                            n_independent=n_independent,\n",
    "                            n_shared=n_shared,\n",
    "                            lambda_sparse=1e-3,\n",
    "                            optimizer_fn=torch.optim.AdamW, \n",
    "                            optimizer_params=dict(lr=lr),\n",
    "                            mask_type=\"sparsemax\",\n",
    "                            verbose=0\n",
    "                            )\n",
    "        unsupervised_model = TabNetPretrainer(**tabnet_params)\n",
    "        return unsupervised_model\n",
    "    \n",
    "\n",
    "    # Train settings\n",
    "    nums_epochs = [10]\n",
    "    batch_sizes = [512]\n",
    "    patience = [10,20]\n",
    "    n_d_a = [16]\n",
    "    n_shared = [8,16]\n",
    "    n_indipendents = [1] \n",
    "    n_steps = [8,9]\n",
    "    gamma = [1.0]\n",
    "    epsilon = [1e-15]\n",
    "    learning_rate = [0.01]\n",
    "    pretraining_ratio = [0.5]\n",
    "    momentum = [0.99]\n",
    "\n",
    "    hyperparameters = list(itertools.product(nums_epochs, batch_sizes, patience, n_d_a, n_indipendents, n_shared, n_steps, gamma, epsilon, learning_rate, pretraining_ratio, momentum))\n",
    "    \n",
    "    current_iter = 0\n",
    "    best_acc = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1; 1/1] START n_neighbors=2, p=1..........................................\n",
      "[CV 1/1; 1/1] END n_neighbors=2, p=1; balanced_accuracy: (test=0.992) f1_weighted: (test=0.999) total time=20.8min\n",
      "---------------------------------\n",
      "Best hyper:  KNeighborsClassifier(n_neighbors=2, p=1)\n",
      "Best score:  0.9920637948245654\n"
     ]
    }
   ],
   "source": [
    "if ml == True:\n",
    "    grid.fit(X, y)\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Best hyper: \", grid.best_estimator_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    best_clf = grid.best_estimator_\n",
    "else:\n",
    "    if clf == 'ffnn':\n",
    "        for batch_size, hidden_size, depth, gamma, batch_norm in hyperparameters:\n",
    "            fix_random(SEED)\n",
    "            \n",
    "            start = time.time()\n",
    "            log_name = \"B\"+str(batch_size)+\"-dim\"+str(hidden_size)+\"-dp\"+str(depth)+\"-ep\"+str(num_epochs)+\"-lr\"+str(learning_rate)+\"-steplr\"+str(step_size)+\"-gamma\"+str(gamma)+\"-BN\"+str(batch_norm)+\"-drop\"+str(drop)\n",
    "            print(log_name, end=\", \")\n",
    "            \n",
    "            writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "            # Create Dataloaders\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "            # Define Architecture\n",
    "            model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "            model.to(device)\n",
    "                    \n",
    "            # Define Loss and Optimizer\n",
    "            criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(list(class_weights.values())).to(device))\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "            # Train the model\n",
    "            model, best_valid_loss = train_model(model, criterion, optimizer, num_epochs, scheduler, train_loader, val_loader, device, writer, log_name)\n",
    "\n",
    "            writer.add_hparams({'hparam/bsize': batch_size, 'hparam/hidden size': hidden_size, 'hparam/depth':depth+2, 'hparam/scheduler': gamma,'hparam/batch norm': batch_norm}, {'best loss': best_valid_loss})\n",
    "            writer.flush()\n",
    "\n",
    "            if best_valid_loss < lowest_loss:\n",
    "                best_model = model\n",
    "                lowest_loss = best_valid_loss\n",
    "                best_model_params = (batch_size, hidden_size, depth, gamma, batch_norm, log_name)\n",
    "\n",
    "            # Log the elapsed time\n",
    "            print(\"-- elpased time:\", time.time() - start)\n",
    "        writer.close()\n",
    "\n",
    "        # # Save the best model and its hyperparameters\n",
    "        # torch.save(best_model.state_dict(), 'models/best_model')\n",
    "        # with open('best_model_params.pkl', 'wb') as f:\n",
    "        #     pickle.dump(best_model_params, f)\n",
    "\n",
    "        # # Load the best model\n",
    "        # if best_model_params:\n",
    "        #     _, _, _, _, _, best_log_name = best_model_params\n",
    "        #     model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "    elif clf == 'tabtransf':\n",
    "        for epochs, batch_size, patience_, dim_embedding_, num_heads_, num_layers_, lr in hyperparameters:\n",
    "\n",
    "            print(f'Iteration {current_iter+1}/{len(hyperparameters)}')\n",
    "            print(f'Hyperparameters: epochs={epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  dim_embedding={dim_embedding_}, \n",
    "                  num_heads={num_heads_}, \n",
    "                  num_layers={num_layers_}, \n",
    "                  lr={lr}')\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=y_val.shape[0], shuffle=False)\n",
    "\n",
    "            model = TabTransformer(train_dataset.num_feature, train_dataset.num_classes).to(torch.device('cuda'))\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "            model, loss_history, val_loss_history = train_model(model, criterion, optimizer, epochs, train_loader, val_loader, device, scheduler, patience_)\n",
    "            \n",
    "            val_loss, y_pred, y_true = test_model(model, criterion, val_loader)\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_params = (epochs, batch_size, patience_, dim_embedding_, num_heads_, num_layers_, lr)\n",
    "\n",
    "            print(f'Hyperparameters: epochs={epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  dim_embedding={dim_embedding_}, \n",
    "                  num_heads={num_heads_}, \n",
    "                  num_layers={num_layers_}, \n",
    "                  lr={lr}')\n",
    "            print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "            current_iter += 1\n",
    "    \n",
    "    elif clf == 'tabnet':\n",
    "        for num_epochs, batch_size, patience_, n_d, n_i, n_s, n_steps_, gamma_, epsilon_, lr, pretraining_ratio_, moment in hyperparameters:\n",
    "    \n",
    "            print(f'Iteration {current_iter+1}/{len(hyperparameters)}')\n",
    "            print(f'Hyperparameters: epochs={num_epochs}, \n",
    "                  batch_size={batch_size}, \n",
    "                  patience={patience_}, \n",
    "                  n_d={n_d}, \n",
    "                  n_indipendent={n_i}, \n",
    "                  n_shared={n_s}, \n",
    "                  n_steps={n_steps_}, \n",
    "                  gamma={gamma_}, \n",
    "                  epsilon={epsilon_}, \n",
    "                  lr={lr}, \n",
    "                  pretraining_ratio={pretraining_ratio_}, \n",
    "                  momentum={moment}')\n",
    "\n",
    "            unsupervised_model = get_unsupervised_model(n_d, n_steps_, n_i, n_s, gamma_, lr)\n",
    "                \n",
    "            unsupervised_model.fit(\n",
    "                X_train=X_train,\n",
    "                eval_set=[X_val],\n",
    "                max_epochs=num_epochs,\n",
    "                patience=patience_,\n",
    "                batch_size=batch_size,\n",
    "                virtual_batch_size=128,\n",
    "                num_workers=0,\n",
    "                drop_last=False,\n",
    "                pretraining_ratio=pretraining_ratio_,\n",
    "            )\n",
    "\n",
    "            model = TabNet(n_d=n_d,\n",
    "                        n_a=n_d,\n",
    "                        n_steps=n_steps_,\n",
    "                        gamma=gamma_,\n",
    "                        optimizer_fn=torch.optim.AdamW,\n",
    "                        n_independent=n_i,\n",
    "                        n_shared=n_s,\n",
    "                        epsilon=epsilon_,\n",
    "                        seed=SEED,\n",
    "                        lambda_sparse=1e-4,\n",
    "                        clip_value=1,\n",
    "                        momentum=moment,\n",
    "                        optimizer_params=dict(lr=lr),\n",
    "                        scheduler_params=dict(step_size=10, gamma=0.9),\n",
    "                        mask_type='sparsemax',\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                        device_name=device,\n",
    "                        output_dim=len(np.unique(y_train)),\n",
    "                        batch_size=batch_size,\n",
    "                        num_epochs=num_epochs,\n",
    "                        unsupervised_model=None,\n",
    "                        verbose=0)\n",
    "            \n",
    "            model.fit_model(X_train, y_train, X_val, y_val, criterion)    \n",
    "            y_pred = model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_pred)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model_params = (num_epochs, batch_size, patience_, n_d, n_i, n_s, n_steps_, gamma_, epsilon_, lr, pretraining_ratio_, moment)\n",
    "            \n",
    "            current_iter += 1\n",
    "\n",
    "    # Save the best model and its hyperparameters\n",
    "    torch.save(best_model.state_dict(), 'models/best_model')\n",
    "    with open('best_model_params.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model_params, f)\n",
    "\n",
    "    # Load the best model\n",
    "    if best_model_params:\n",
    "        if clf == 'ffnn':\n",
    "            batch_size, hidden_size, depth, gamma, batch_norm, best_log_name = best_model_params\n",
    "            model = FeedForwardPlus(train_dataset.num_features, train_dataset.num_classes, hidden_size, depth, batch_norm=batch_norm)\n",
    "        elif clf == 'tabtransf':\n",
    "            epochs, batch_size, patience, dim_embedding, num_heads, num_layers, lr = best_model_params\n",
    "            model = TabTransformer(train_dataset.num_features, train_dataset.num_classes, dim_embedding=dim_embedding, num_heads=num_heads, num_layers=num_layers, lr=lr)\n",
    "        elif clf == 'tabnet':\n",
    "            num_epochs, batch_size, patience, n_d, n_i, n_s, n_steps, gamma, epsilon, lr, pretraining_ratio, moment = best_model_params\n",
    "            model = TabNet(n_d=n_d,\n",
    "                        n_a=n_d,\n",
    "                        n_steps=n_steps,\n",
    "                        gamma=gamma,\n",
    "                        optimizer_fn=torch.optim.AdamW,\n",
    "                        n_independent=n_i,\n",
    "                        n_shared=n_s,\n",
    "                        epsilon=epsilon,\n",
    "                        seed=SEED,\n",
    "                        lambda_sparse=1e-4,\n",
    "                        clip_value=1,\n",
    "                        momentum=moment,\n",
    "                        optimizer_params=dict(lr=lr),\n",
    "                        scheduler_params=dict(step_size=10, gamma=0.9),\n",
    "                        mask_type='sparsemax',\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                        device_name=device,\n",
    "                        output_dim=len(np.unique(y_train)),\n",
    "                        batch_size=batch_size,\n",
    "                        num_epochs=num_epochs,\n",
    "                        unsupervised_model=None,\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1516\n",
      "           1       1.00      1.00      1.00     18249\n",
      "           2       1.00      1.00      1.00      5448\n",
      "           3       1.00      0.99      0.99      1358\n",
      "           4       1.00      0.98      0.99        62\n",
      "           5       1.00      1.00      1.00      2068\n",
      "           6       1.00      1.00      1.00      5156\n",
      "           7       0.99      1.00      0.99        96\n",
      "           8       1.00      1.00      1.00     21421\n",
      "           9       1.00      1.00      1.00      6327\n",
      "\n",
      "    accuracy                           1.00     61701\n",
      "   macro avg       1.00      1.00      1.00     61701\n",
      "weighted avg       1.00      1.00      1.00     61701\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if ml:\n",
    "    classes = best_clf.classes_\n",
    "    \n",
    "    if overfit:\n",
    "        y_pred = best_clf.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        report = print(classification_report(y_test, y_pred))    \n",
    "    else:\n",
    "        y_pred = best_clf.predict(X_val)\n",
    "        cm = confusion_matrix(y_val, y_pred, labels=classes)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "        disp.plot()\n",
    "        print(classification_report(y_val, y_pred))\n",
    "\n",
    "else:\n",
    "    if clf == 'ffnn':\n",
    "        # Evaluate the best model on the test set\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_sizes[0])\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        y_test, y_pred_c, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "    elif clf == 'tabtransf':\n",
    "        test_loader = DataLoader(test_dataset, batch_size=y_test.shape[0], shuffle=False)\n",
    "\n",
    "        _, y_pred, y_true = test_model(model, criterion, test_loader)\n",
    "        y_pred_c = y_pred.argmax(dim=1, keepdim=True).squeeze()\n",
    "\n",
    "    elif clf == 'tabnet':\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=y_test.max().item() + 1)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_test.max().item() + 1)\n",
    "        disp.plot()\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    if clf != 'tabnet':\n",
    "        # Print Accuracy, Precision, F1 Score and Confusion Matrix\n",
    "        print(f\"Accuracy: {:.4f} --\\t Precision: {:.4f} --\\t F1: {:.4f} --\\t Balanced Accuracy: {:.4f}\".format( \n",
    "            tm.MulticlassAccuracy().update(y_pred_c, y_test).compute().item(), \n",
    "            tm.MulticlassPrecision(num_classes=y_test.max().item() + 1).update(y_pred, y_test).compute().item(),\n",
    "            tm.MulticlassF1Score(num_classes=y_test.max().item() + 1, ).update(y_pred, y_test),\n",
    "            balanced_accuracy_score(y_test.cpu().numpy(), y_pred_c.cpu().numpy())))\n",
    "\n",
    "        print(classification_report(y_test.cpu().numpy(), y_pred_c.cpu().numpy()))\n",
    "        conf_matrix = tm.MulticlassConfusionMatrix(num_classes=y_test.max().item() + 1)\n",
    "        conf_matrix.update(y_pred_c, y_test)\n",
    "        ConfusionMatrixDisplay(conf_matrix.compute().cpu().numpy()).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99931929790441\n",
      "0.9970973963158316\n",
      "0.999319034493822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Classification Report}\n",
      "\\label{tab:classification_report}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Class & Precision & Recall & F1-Score & Support \\\\\n",
      "\\midrule\n",
      "0 & 1.00 & 1.00 & 1.00 & 1516.00 \\\\\n",
      "1 & 1.00 & 1.00 & 1.00 & 18249.00 \\\\\n",
      "2 & 1.00 & 1.00 & 1.00 & 5448.00 \\\\\n",
      "3 & 1.00 & 0.99 & 0.99 & 1358.00 \\\\\n",
      "4 & 1.00 & 0.98 & 0.99 & 62.00 \\\\\n",
      "5 & 1.00 & 1.00 & 1.00 & 2068.00 \\\\\n",
      "6 & 1.00 & 1.00 & 1.00 & 5156.00 \\\\\n",
      "7 & 0.99 & 1.00 & 0.99 & 96.00 \\\\\n",
      "8 & 1.00 & 1.00 & 1.00 & 21421.00 \\\\\n",
      "9 & 1.00 & 1.00 & 1.00 & 6327.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "# Parse the classification report into a pandas DataFrame\n",
    "lines = report.splitlines()\n",
    "\n",
    "# Collect rows for DataFrame\n",
    "rows = []\n",
    "for line in lines[2:-3]:  # Ignore the header and footer\n",
    "    row = line.split()\n",
    "    if len(row) < 2:\n",
    "        continue\n",
    "    # Combine the first column (e.g., class label) and the rest\n",
    "    label = row[0]\n",
    "    values = row[1:]\n",
    "    rows.append([label] + list(map(float, values)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"])\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = df.to_latex(index=False, float_format=\"%.2f\", caption=\"Classification Report\", label=\"tab:classification_report\")\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
